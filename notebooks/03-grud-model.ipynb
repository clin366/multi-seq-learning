{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(os.path.pardir)\n",
    "# load data from file \n",
    "import numpy as np \n",
    "save_file_name = ['fea_seq.npy', 'last_observation_seq.npy', 'label_seq.npy', 'masking_seq.npy',\n",
    "                   'delta_seq.npy', 'train_valid_test_split.npy']\n",
    "save_folder = 'data/raw'\n",
    "saved_arrays = []\n",
    "for file_name in save_file_name:\n",
    "    saved_arrays.append(np.load(os.path.join(save_folder, file_name)))\n",
    "[fea_seq, last_observation_seq, label_seq, masking_seq, delta_seq, train_valid_test_split] = saved_arrays\n",
    "\n",
    "# train-test-split \n",
    "train_index = [k for k in range(train_valid_test_split[0])]\n",
    "dev_index = [k for k in range(train_valid_test_split[0], \n",
    "                               train_valid_test_split[0] + train_valid_test_split[1])]\n",
    "test_index = [k for k in range(train_valid_test_split[0] + train_valid_test_split[1],\n",
    "              train_valid_test_split[0] + train_valid_test_split[1] + train_valid_test_split[2])]\n",
    "\n",
    "def get_array_by_index_range(nparray_list, label_array, index_range):\n",
    "    '''\n",
    "    nparray_list: list of nparrays to select according to index range \n",
    "    label_array: select the labels from label array\n",
    "    '''\n",
    "    # get non-na index\n",
    "    non_na_index = []\n",
    "    for index in index_range:\n",
    "        if not np.isnan(label_array[index]):\n",
    "            non_na_index.append(index)\n",
    "    \n",
    "    return [k[non_na_index] for k in nparray_list], label_array[non_na_index].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize delta\n",
    "\n",
    "delta_seq = (delta_seq - np.mean(delta_seq)) / np.std(delta_seq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split set to train, test and dev sets \n",
    "# train set\n",
    "[fea_train, last_train, masking_train, delta_train], label_train =  get_array_by_index_range([fea_seq,last_observation_seq, masking_seq, delta_seq\n",
    "                                                                 ], label_seq, train_index)\n",
    "# dev set \n",
    "[fea_dev, last_dev, masking_dev, delta_dev], label_dev =  get_array_by_index_range([fea_seq, last_observation_seq, masking_seq, delta_seq\n",
    "                                                           ], label_seq, dev_index)\n",
    "# test set \n",
    "[fea_test, last_test, masking_test, delta_test], label_test =  get_array_by_index_range([fea_seq, last_observation_seq, masking_seq, delta_seq\n",
    "                                                              ], label_seq, test_index)\n",
    "\n",
    "def normalize_feature(fea_train, array_list):\n",
    "    \"\"\"\n",
    "    array_list: [fea_dev, fea_test, last_train, last_dev, last_test] to normalize \n",
    "    \"\"\"\n",
    "    train_mean = np.nanmean(fea_train, axis=0)\n",
    "    train_std = np.nanstd(fea_train, axis=0)\n",
    "    def norm_arr(nparr):\n",
    "        return(nparr - train_mean)/train_std\n",
    "    return (norm_arr(fea_train), [norm_arr(k) for k in array_list])\n",
    "\n",
    "fea_train, [fea_dev, fea_test, last_train, last_dev, last_test] = normalize_feature(fea_train,\n",
    "                                                                                   [fea_dev, fea_test, \n",
    "                                                                                    last_train, last_dev,\n",
    "                                                                                    last_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record mean after normalization \n",
    "x_mean_aft_nor = np.nanmean(fea_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, filter_square_matrix, bias=True):\n",
    "        '''\n",
    "        filter_square_matrix : filter square matrix, whose each elements is 0 or 1.\n",
    "        '''\n",
    "        super(FilterLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        self.filter_square_matrix = None\n",
    "        if use_gpu:\n",
    "            self.filter_square_matrix = Variable(filter_square_matrix.cuda(), requires_grad=False)\n",
    "        else:\n",
    "            self.filter_square_matrix = Variable(filter_square_matrix, requires_grad=False)\n",
    "        \n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "#         print(self.weight.data)\n",
    "#         print(self.bias.data)\n",
    "\n",
    "    def forward(self, input):\n",
    "#         print(self.filter_square_matrix.mul(self.weight))\n",
    "        return F.linear(input, self.filter_square_matrix.mul(self.weight), self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'in_features=' + str(self.in_features) \\\n",
    "            + ', out_features=' + str(self.out_features) \\\n",
    "            + ', bias=' + str(self.bias is not None) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUD(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, X_mean, output_last = True, dropout=0):\n",
    "        \"\"\"\n",
    "        Recurrent Neural Networks for Multivariate Times Series with Missing Values\n",
    "        GRU-D: GRU exploit two representations of informative missingness patterns, i.e., masking and time interval.\n",
    "        cell_size is the size of cell_state.\n",
    "        \n",
    "        GRU-D:\n",
    "            input_size: variable dimension of each time\n",
    "            hidden_size: dimension of hidden_state\n",
    "            mask_size: dimension of masking vector\n",
    "            X_mean: the mean of the historical input data\n",
    "        \"\"\"\n",
    "        \n",
    "        super(GRUD, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.delta_size = input_size\n",
    "        self.mask_size = input_size\n",
    "        \n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            self.identity = torch.eye(input_size).cuda()\n",
    "            self.zeros = Variable(torch.zeros(input_size).cuda())\n",
    "            self.X_mean = Variable(torch.Tensor(X_mean).cuda())\n",
    "        else:\n",
    "            self.identity = torch.eye(input_size)\n",
    "            self.zeros = Variable(torch.zeros(input_size))\n",
    "            self.X_mean = Variable(torch.Tensor(X_mean))\n",
    "        \n",
    "        self.zl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size)\n",
    "        self.rl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size)\n",
    "        self.hl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size)\n",
    "        \n",
    "        self.gamma_x_l = FilterLinear(self.delta_size, self.delta_size, self.identity)\n",
    "        \n",
    "        self.gamma_h_l = nn.Linear(self.delta_size, self.delta_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def step(self, x, x_last_obsv, x_mean, h, mask, delta):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        dim_size = x.shape[1]\n",
    "        \n",
    "        delta_x = torch.exp(-torch.max(self.zeros, self.gamma_x_l(delta)))\n",
    "        delta_h = torch.exp(-torch.max(self.zeros, self.gamma_h_l(delta)))\n",
    "        \n",
    "        tmp = mask * x + (1 - mask) * (delta_x * x_last_obsv)\n",
    "        x = mask * x + (1 - mask) * (delta_x * x_last_obsv + (1 - delta_x) * x_mean)\n",
    "        h = delta_h * h\n",
    "        \n",
    "        combined = torch.cat((x, h, mask), 1)\n",
    "        z = torch.sigmoid(self.zl(combined))\n",
    "        r = torch.sigmoid(self.rl(combined))\n",
    "        combined_r = torch.cat((x, r * h, mask), 1)\n",
    "        h_tilde = torch.tanh(self.hl(combined_r))\n",
    "        h = (1 - z) * h + z * h_tilde\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        type_size = input.size(1)\n",
    "        step_size = input.size(2)\n",
    "        spatial_size = input.size(3)\n",
    "        \n",
    "        Hidden_State = self.initHidden(batch_size)\n",
    "        \n",
    "        def squeeze_d1(matrix):\n",
    "            return torch.squeeze(matrix, dim=1)\n",
    "        X = squeeze_d1(input[:,0,:,:])\n",
    "        X_last_obsv = squeeze_d1(input[:,1,:,:])\n",
    "        Mask = squeeze_d1(input[:,2,:,:])\n",
    "        Delta = squeeze_d1(input[:,3,:,:])\n",
    "        \n",
    "        outputs = None\n",
    "        for i in range(step_size):\n",
    "#             print(\"x_mean size: \")\n",
    "#             print(self.X_mean.size())\n",
    "            Hidden_State = self.step(squeeze_d1(X[:,i:i+1,:])\\\n",
    "                                     , squeeze_d1(X_last_obsv[:,i:i+1,:])\\\n",
    "                                     , squeeze_d1(self.X_mean[:,i:i+1,:])\\\n",
    "                                     , Hidden_State\\\n",
    "                                     , squeeze_d1(Mask[:,i:i+1,:])\\\n",
    "                                     , squeeze_d1(Delta[:,i:i+1,:]))\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "                \n",
    "        if self.output_last:\n",
    "            last_hs = outputs[:,-1,:]\n",
    "            output = F.relu(self.fc1(last_hs))\n",
    "            output = self.dropout(output)\n",
    "            output = self.fc2(output)\n",
    "            return output\n",
    "        else:\n",
    "            raise Exception(\"Not output last\")\n",
    "\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset for grud \n",
    "def dataset_aggregation(feature_array, last_obsv, mask, delta):\n",
    "    # expand dimension of array\n",
    "    def expd(arr):\n",
    "        return np.expand_dims(arr, axis=1)\n",
    "    return np.concatenate((expd(feature_array), expd(last_obsv), expd(mask), expd(delta)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_aggregation for train, dev, test \n",
    "# train_aggr = dataset_aggregation(fea_train, last_train, masking_train, delta_train)\n",
    "train_aggr = dataset_aggregation(last_train, last_train, masking_train, delta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_aggr = dataset_aggregation(fea_dev, last_dev, masking_dev, delta_dev)\n",
    "# test_aggr = dataset_aggregation(fea_test, last_test, masking_test, delta_test)\n",
    "dev_aggr = dataset_aggregation(last_dev, last_dev, masking_dev, delta_dev)\n",
    "test_aggr = dataset_aggregation(last_test, last_test, masking_test, delta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aggr[0:1,:].shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean_aft_nor = np.expand_dims(x_mean_aft_nor, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_grud(X_train, y_train, X_valid, y_valid, X_test, y_test, config, x_mean_aft_nor, dropout = 0):\n",
    "    # no shuffle, keep original order \n",
    "    # swap axes for back propagation \n",
    "#     def swap_axes(nparr):\n",
    "#         return nparr.swapaxes(0,1)\n",
    "#     X_train = swap_axes(X_train)\n",
    "#     X_valid = swap_axes(X_valid)\n",
    "#     X_test = swap_axes(X_test)\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = X_train.shape[3]\n",
    "    h = config[\"h\"]\n",
    "    t = X_train.shape[2]\n",
    "    output_dim = 1\n",
    "    dropout = config[\"drop\"]\n",
    "    \n",
    "    model = GRUD(input_size, h, x_mean_aft_nor, output_last = True, dropout=dropout)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    device = torch.device('cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", patience=10, factor=0.5, verbose=True)\n",
    "    \n",
    "    def train(model, batchsize, X_train, y_train, optimizer, criterion):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        total_n = X_train.shape[0]\n",
    "        num_batches = math.ceil(total_n / batchsize)\n",
    "        for batch in range(num_batches):\n",
    "            start = batch*batchsize\n",
    "            end = (batch+1)*batchsize\n",
    "            optimizer.zero_grad()\n",
    "            batch_X = torch.Tensor(X_train[start:end, :])\n",
    "            batch_y = torch.Tensor(y_train[start:end])\n",
    "            predictions = model.forward(batch_X).squeeze(1)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        return epoch_loss / num_batches \n",
    "    \n",
    "    def evaluate(model, X_valid, y_valid, criterion):\n",
    "        epoch_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_X = torch.Tensor(X_valid)\n",
    "            batch_y = torch.Tensor(y_valid)\n",
    "            predictions = model.forward(batch_X).squeeze(1)\n",
    "            epoch_loss = criterion(predictions, batch_y).item()\n",
    "        return epoch_loss\n",
    "\n",
    "    def predict(model, X_test):\n",
    "        epoch_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_X = torch.Tensor(X_test)\n",
    "            predictions = model.forward(batch_X).squeeze(1)\n",
    "            predictions = predictions.cpu().data.numpy()\n",
    "        return predictions\n",
    "\n",
    "    # timing\n",
    "#     start_time = time.time()\n",
    "#     predictions = predict(model, X_test)\n",
    "#     print(predictions.shape)\n",
    "#     print(predictions)\n",
    "#     end_time = time.time()\n",
    "#     print(end_time-start_time)\n",
    "#     assert False\n",
    "     \n",
    "    best_valid = 999999.0\n",
    "    rand = random.randint(0,100000)\n",
    "    print('epoch train_loss valid_loss')\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        train_loss = train(model, config[\"batchsize\"], X_train, y_train, optimizer, criterion)\n",
    "        valid_loss = evaluate(model, X_valid, y_valid, criterion)\n",
    "        scheduler.step(valid_loss)\n",
    "        if valid_loss <= best_valid:\n",
    "            # save model\n",
    "            best_valid = valid_loss\n",
    "            print(epoch, train_loss, valid_loss, 'saving model')\n",
    "            torch.save(model, 'models/lstm_%d.pt' %rand)\n",
    "        else:\n",
    "            print(epoch, train_loss, valid_loss)\n",
    "\n",
    "    model = torch.load('models/lstm_%d.pt' %rand)\n",
    "\n",
    "    predictions = predict(model, X_test)\n",
    "    mae = np.mean(np.absolute(predictions-y_test))\n",
    "    print(\"mae: \", mae)\n",
    "    mse = np.mean((predictions - y_test)**2)\n",
    "    print(\"mse: \", mse)\n",
    "#     corr = np.corrcoef(predictions,y_test)[0][1]\n",
    "#     print(\"corr: \", corr)\n",
    "#     true_label = (y_test >= 0)\n",
    "#     sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mean_aft_nor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch train_loss valid_loss\n",
      "0 144.09268261137464 112.29701232910156 saving model\n",
      "1 143.32800220307848 111.58708190917969 saving model\n",
      "2 142.55936177571616 110.85371398925781 saving model\n",
      "3 141.67873164585657 110.01898193359375 saving model\n",
      "4 140.76136452811105 109.03749084472656 saving model\n",
      "5 139.59604971749442 107.8071060180664 saving model\n",
      "6 138.01105753580728 106.09915161132812 saving model\n",
      "7 136.02139572870163 103.64372253417969 saving model\n",
      "8 132.81409672328405 99.7139663696289 saving model\n",
      "9 127.34080069405692 92.69762420654297 saving model\n",
      "10 118.0801511492048 79.47148895263672 saving model\n",
      "11 100.42741811843146 58.703277587890625 saving model\n",
      "12 77.838927314395 39.956932067871094 saving model\n",
      "13 58.35975156511579 29.307415008544922 saving model\n",
      "14 46.32283465067545 23.608463287353516 saving model\n",
      "15 39.20863233293806 20.46603775024414 saving model\n",
      "16 36.831469127110076 18.812332153320312 saving model\n",
      "17 32.338939757574174 18.036155700683594 saving model\n",
      "18 30.797796476454963 17.74964141845703 saving model\n",
      "19 30.83486729576474 17.71417999267578 saving model\n",
      "20 31.34781401497977 17.79169464111328\n",
      "21 29.170764559791202 17.893917083740234\n",
      "22 30.498323258899507 17.97453498840332\n",
      "23 30.115161441621325 18.066144943237305\n",
      "24 29.646217981974285 18.171003341674805\n",
      "25 29.026562009538925 18.229938507080078\n",
      "26 29.479726064772834 18.256216049194336\n",
      "27 28.65731207529704 18.276750564575195\n",
      "28 28.738877932230633 18.317716598510742\n",
      "29 31.289889063153947 18.336387634277344\n",
      "Epoch    31: reducing learning rate of group 0 to 5.0000e-05.\n",
      "30 29.6557130359468 18.275718688964844\n",
      "31 29.247105553036643 18.271759033203125\n",
      "32 31.185950370061967 18.24042510986328\n",
      "33 29.065045810881116 18.252052307128906\n",
      "34 30.505957694280717 18.27936553955078\n",
      "35 30.334595453171502 18.282649993896484\n",
      "36 29.366812251863024 18.2868595123291\n",
      "37 29.42408157530285 18.30779266357422\n",
      "38 29.253909065609886 18.34443473815918\n",
      "39 29.972398303803942 18.32929039001465\n",
      "40 30.409004938034784 18.31169891357422\n",
      "Epoch    42: reducing learning rate of group 0 to 2.5000e-05.\n",
      "41 29.616327694484166 18.329275131225586\n",
      "42 30.165613446916854 18.315698623657227\n",
      "43 29.891684123447963 18.307186126708984\n",
      "44 29.082445735023136 18.30759620666504\n",
      "45 27.87551148732503 18.307357788085938\n",
      "46 29.10954389118013 18.30304718017578\n",
      "47 29.744760558718728 18.30430030822754\n",
      "48 30.070247650146484 18.306013107299805\n",
      "49 29.725963910420734 18.307395935058594\n",
      "mae:  3.5979709735586622\n",
      "mse:  18.38896302688491\n"
     ]
    }
   ],
   "source": [
    "config = {'h':64, 'lr':0.0001, 'num_epochs':50, 'batchsize':32, 'drop':0.5}\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_grud(train_aggr, label_train, dev_aggr, label_dev, test_aggr, label_test, config, x_mean_aft_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch train_loss valid_loss\n",
      "0 144.09613000778924 112.28630065917969 saving model\n",
      "1 143.30677759079705 111.55638122558594 saving model\n",
      "2 142.51056598481676 110.79736328125 saving model\n",
      "3 141.60945311046783 109.93473815917969 saving model\n",
      "4 140.5901391165597 108.89582061767578 saving model\n",
      "5 139.3742937360491 107.51197052001953 saving model\n",
      "6 137.61573973156158 105.55892181396484 saving model\n",
      "7 135.25978379022507 102.72268676757812 saving model\n",
      "8 131.56709362211683 98.08820343017578 saving model\n",
      "9 125.22598520914714 89.62700653076172 saving model\n",
      "10 113.65036828177315 73.9071044921875 saving model\n",
      "11 93.41203689575195 52.07622146606445 saving model\n",
      "12 70.14385414123535 35.50328826904297 saving model\n",
      "13 52.85699953351702 26.624557495117188 saving model\n",
      "14 42.01252442314511 21.877925872802734 saving model\n",
      "15 35.05150236402239 19.378318786621094 saving model\n",
      "16 32.28873820531936 18.186214447021484 saving model\n",
      "17 28.633030528113956 17.746469497680664 saving model\n",
      "18 28.058009510948544 17.7139949798584 saving model\n",
      "19 27.216539519173757 17.874530792236328\n",
      "20 26.88344937279111 18.082529067993164\n",
      "21 25.70840563092913 18.29402732849121\n",
      "22 25.99390170687721 18.44550895690918\n",
      "23 27.115379242669967 18.58595848083496\n",
      "24 25.931588490804035 18.696491241455078\n",
      "25 26.47777648199172 18.754596710205078\n",
      "26 26.16776502700079 18.789718627929688\n",
      "27 25.664913086664107 18.783254623413086\n",
      "28 25.81522764478411 18.821430206298828\n",
      "Epoch    30: reducing learning rate of group 0 to 5.0000e-05.\n",
      "29 26.783132553100586 18.845806121826172\n",
      "30 26.39972804841541 18.85045051574707\n",
      "31 25.379626047043573 18.858421325683594\n",
      "32 26.582955632890975 18.863750457763672\n",
      "33 26.25661323184059 18.86872100830078\n",
      "34 26.12972722734724 18.87668800354004\n",
      "35 26.08494168236142 18.905118942260742\n",
      "36 24.803148405892507 18.921388626098633\n",
      "37 25.79754538763137 18.941204071044922\n",
      "38 26.103511083693732 18.948471069335938\n",
      "39 26.268742788405646 18.934494018554688\n",
      "Epoch    41: reducing learning rate of group 0 to 2.5000e-05.\n",
      "40 26.50045771825881 18.924028396606445\n",
      "41 26.120178449721564 18.91893196105957\n",
      "42 26.169327100118 18.907926559448242\n",
      "43 27.138863699776785 18.894607543945312\n",
      "44 26.132085391453334 18.89594078063965\n",
      "45 25.254767690386092 18.89596176147461\n",
      "46 26.93148594810849 18.895849227905273\n",
      "47 25.74541446140834 18.8938045501709\n",
      "48 26.2378937403361 18.897119522094727\n",
      "49 26.052241824922106 18.893882751464844\n",
      "mae:  3.6097934407636156\n",
      "mse:  18.50284117175752\n"
     ]
    }
   ],
   "source": [
    "config = {'h':64, 'lr':0.0001, 'num_epochs':50, 'batchsize':32, 'drop':0.2}\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_grud(train_aggr, label_train, dev_aggr, label_dev, test_aggr, label_test, config, x_mean_aft_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch train_loss valid_loss\n",
      "0 144.98113614036924 113.31004333496094 saving model\n",
      "1 144.58987499418714 112.9237289428711 saving model\n",
      "2 144.17743610200426 112.51087188720703 saving model\n",
      "3 143.74056970505487 112.07484436035156 saving model\n",
      "4 143.27923184349424 111.61736297607422 saving model\n",
      "5 142.7927031744094 111.13607788085938 saving model\n",
      "6 142.27810632614862 110.62649536132812 saving model\n",
      "7 141.7314689272926 110.08468627929688 saving model\n",
      "8 141.14879208519346 109.50629425048828 saving model\n",
      "9 140.52348145984467 108.88167572021484 saving model\n",
      "10 139.84443846203033 108.1917953491211 saving model\n",
      "11 139.09578850155785 107.42391967773438 saving model\n",
      "12 138.26453145345053 106.56607055664062 saving model\n",
      "13 137.33827609107607 105.60845947265625 saving model\n",
      "14 136.302249000186 104.53165435791016 saving model\n",
      "15 135.13734109061105 103.32125854492188 saving model\n",
      "16 133.82503509521484 101.95484161376953 saving model\n",
      "17 132.3396987915039 100.39956665039062 saving model\n",
      "18 130.6502943493071 98.6193618774414 saving model\n",
      "19 128.71471441359748 96.56657409667969 saving model\n",
      "20 126.48058210100446 94.18038940429688 saving model\n",
      "21 123.87660326276507 91.38201141357422 saving model\n",
      "22 120.81530162266323 88.07087707519531 saving model\n",
      "23 117.18032600766136 84.11591339111328 saving model\n",
      "24 112.82079878307525 79.35823822021484 saving model\n",
      "25 107.55237815493629 73.61282348632812 saving model\n",
      "26 101.16705812726703 66.70652770996094 saving model\n",
      "27 93.44974336170014 58.52497100830078 saving model\n",
      "28 84.35648600260417 49.416316986083984 saving model\n",
      "29 74.32162321181525 40.233577728271484 saving model\n",
      "30 64.15442330496651 32.062503814697266 saving model\n",
      "31 54.84752078283401 25.775007247924805 saving model\n",
      "32 47.16508538382394 21.62459373474121 saving model\n",
      "33 41.36737278529576 19.30209732055664 saving model\n",
      "34 37.277069137209935 18.26021385192871 saving model\n",
      "35 34.511260986328125 17.982364654541016 saving model\n",
      "36 32.67354243142264 18.091733932495117\n",
      "37 31.44357867467971 18.355979919433594\n",
      "38 30.59757559640067 18.650115966796875\n",
      "39 29.99096834091913 18.916357040405273\n",
      "40 29.53436519986107 19.13420295715332\n",
      "41 29.17370096842448 19.301572799682617\n",
      "42 28.876895041692826 19.424209594726562\n",
      "43 28.624465669904435 19.510244369506836\n",
      "44 28.404378436860583 19.56771469116211\n",
      "45 28.208997635614303 19.603534698486328\n",
      "Epoch    47: reducing learning rate of group 0 to 5.0000e-05.\n",
      "46 28.033306666782924 19.623308181762695\n",
      "47 27.881920678274973 19.629850387573242\n",
      "48 27.807712645757768 19.635059356689453\n",
      "49 27.736511730012438 19.63833236694336\n",
      "mae:  3.7214990907464145\n",
      "mse:  19.461000378758573\n"
     ]
    }
   ],
   "source": [
    "config = {'h':32, 'lr':0.0001, 'num_epochs':50, 'batchsize':32, 'drop':0}\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_grud(train_aggr, label_train, dev_aggr, label_dev, test_aggr, label_test, config, x_mean_aft_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch train_loss valid_loss\n",
      "0 144.08581906273253 112.28168487548828 saving model\n",
      "1 143.2817153930664 111.54412841796875 saving model\n",
      "2 142.4728273664202 110.77467346191406 saving model\n",
      "3 141.59358433314733 109.9035415649414 saving model\n",
      "4 140.56763930547805 108.83810424804688 saving model\n",
      "5 139.2681179954892 107.39895629882812 saving model\n",
      "6 137.4923328218006 105.37459564208984 saving model\n",
      "7 135.01947203136626 102.42082214355469 saving model\n",
      "8 131.2140372140067 97.54923248291016 saving model\n",
      "9 124.59526025681268 88.57099151611328 saving model\n",
      "10 112.18622716267903 72.04300689697266 saving model\n",
      "11 91.30404772077289 50.12971496582031 saving model\n",
      "12 67.83551270621163 34.187705993652344 saving model\n",
      "13 50.75630832853771 25.747900009155273 saving model\n",
      "14 40.43479456220354 21.32763671875 saving model\n",
      "15 34.212643895830425 19.054880142211914 saving model\n",
      "16 30.385031336829776 18.025062561035156 saving model\n",
      "17 28.04489312853132 17.704607009887695 saving model\n",
      "18 26.653306189037504 17.75325584411621\n",
      "19 25.85014452253069 17.96070098876953\n",
      "20 25.39628878093901 18.208173751831055\n",
      "21 25.141703060695104 18.43754005432129\n",
      "22 24.99763316199893 18.626754760742188\n",
      "23 24.91399960290818 18.77260398864746\n",
      "24 24.86339555467878 18.880178451538086\n",
      "25 24.831071172441757 18.957111358642578\n",
      "26 24.80912935166132 19.010866165161133\n",
      "27 24.793297631399973 19.04771614074707\n",
      "Epoch    29: reducing learning rate of group 0 to 5.0000e-05.\n",
      "28 24.781258537655784 19.072553634643555\n",
      "29 24.759085019429524 19.08348274230957\n",
      "30 24.75539747873942 19.09384536743164\n",
      "31 24.751684915451776 19.102664947509766\n",
      "32 24.748178709120978 19.110036849975586\n",
      "33 24.74487813313802 19.116147994995117\n",
      "34 24.741758437383744 19.121198654174805\n",
      "35 24.7387942359561 19.12535285949707\n",
      "36 24.735966909499396 19.12874984741211\n",
      "37 24.733255295526412 19.131515502929688\n",
      "38 24.730648313249862 19.133743286132812\n",
      "Epoch    40: reducing learning rate of group 0 to 2.5000e-05.\n",
      "39 24.728131975446427 19.13553237915039\n",
      "40 24.71967433747791 19.136920928955078\n",
      "41 24.718586785452707 19.138599395751953\n",
      "42 24.7174106325422 19.14018440246582\n",
      "43 24.71623061952137 19.141643524169922\n",
      "44 24.715059280395508 19.142976760864258\n",
      "45 24.71389607020787 19.14419174194336\n",
      "46 24.712739354088193 19.145307540893555\n",
      "47 24.711591357276554 19.14631462097168\n",
      "48 24.710448764619372 19.147239685058594\n",
      "49 24.709311076572963 19.1480770111084\n",
      "mae:  3.5519404056643653\n",
      "mse:  17.92563063501066\n"
     ]
    }
   ],
   "source": [
    "config = {'h':64, 'lr':0.0001, 'num_epochs':50, 'batchsize':32, 'drop':0}\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_grud(train_aggr, label_train, dev_aggr, label_dev, test_aggr, label_test, config, x_mean_aft_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch train_loss valid_loss\n",
      "0 145.50146702357702 113.42267608642578 saving model\n",
      "1 144.22535414922805 112.1179428100586 saving model\n",
      "2 142.71865554082962 110.42972564697266 saving model\n",
      "3 140.66197313581193 107.91881561279297 saving model\n",
      "4 137.26863388788132 103.06591033935547 saving model\n",
      "5 129.83041054861886 91.03114318847656 saving model\n",
      "6 109.74551464262463 57.65034484863281 saving model\n",
      "7 66.62122354053315 20.20960235595703 saving model\n",
      "8 35.84184605734689 18.501569747924805 saving model\n",
      "9 28.93174916221982 19.746389389038086\n",
      "10 27.04877049582345 19.373741149902344\n",
      "11 26.153835932413738 19.11964225769043\n",
      "12 25.66512530190604 19.05242347717285\n",
      "13 25.376947266714915 19.03957176208496\n",
      "14 25.206623894827707 19.03276252746582\n",
      "15 25.104502587091353 19.026987075805664\n",
      "16 25.035078366597492 19.017995834350586\n",
      "17 24.98800159635998 19.012653350830078\n",
      "18 24.950860023498535 18.98025894165039\n",
      "Epoch    20: reducing learning rate of group 0 to 5.0000e-05.\n",
      "19 24.932546252296085 18.988656997680664\n",
      "20 24.877528735569545 19.011911392211914\n",
      "21 24.86887486775716 19.03880500793457\n",
      "22 24.85765620640346 19.055940628051758\n",
      "23 24.847815195719402 19.065481185913086\n",
      "24 24.839374178931827 19.07048225402832\n",
      "25 24.831968761625745 19.072969436645508\n",
      "26 24.825314430963424 19.0740909576416\n",
      "27 24.819215274992445 19.074480056762695\n",
      "28 24.81343005952381 19.074569702148438\n",
      "29 24.81059355962844 19.080181121826172\n",
      "Epoch    31: reducing learning rate of group 0 to 2.5000e-05.\n",
      "30 24.803212392897834 19.07727813720703\n",
      "31 24.782860801333474 19.080486297607422\n",
      "32 24.781256494067964 19.086118698120117\n",
      "33 24.77889160882859 19.090925216674805\n",
      "34 24.776540120442707 19.094701766967773\n",
      "35 24.774288722446986 19.097627639770508\n",
      "36 24.77212905883789 19.099872589111328\n",
      "37 24.77005436306908 19.101591110229492\n",
      "38 24.768050330025808 19.102901458740234\n",
      "39 24.766110783531552 19.103891372680664\n",
      "40 24.764229047866095 19.104631423950195\n",
      "Epoch    42: reducing learning rate of group 0 to 1.2500e-05.\n",
      "41 24.762401217506046 19.10517120361328\n",
      "42 24.752583549136208 19.10649299621582\n",
      "43 24.751867657616025 19.108413696289062\n",
      "44 24.7509761991955 19.110212326049805\n",
      "45 24.75007493155343 19.11182975769043\n",
      "46 24.74918170202346 19.11326026916504\n",
      "47 24.748297055562336 19.114543914794922\n",
      "48 24.747419856843493 19.115676879882812\n",
      "49 24.74655578249977 19.116682052612305\n",
      "mae:  4.018142971322557\n",
      "mse:  22.650426252902005\n"
     ]
    }
   ],
   "source": [
    "config = {'h':128, 'lr':0.0001, 'num_epochs':50, 'batchsize':32, 'drop':0}\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_grud(train_aggr, label_train, dev_aggr, label_dev, test_aggr, label_test, config, x_mean_aft_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_train[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:airpol]",
   "language": "python",
   "name": "conda-env-airpol-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
