{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(os.path.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_fea = pd.read_csv('data/external/atlanta_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_path = 'data/external/seed_common.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_terms = []\n",
    "with open(seed_path, 'r') as fi:\n",
    "    line = fi.readline().strip().replace(' ', '_')\n",
    "    while line:\n",
    "        seed_terms.append(line)\n",
    "        line = fi.readline().strip().replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_terms.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_terms = [k for k in trend_fea.columns if k in seed_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_trend_df = trend_fea[merge_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_trend_df.index = pd.to_datetime(trend_fea.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_trend_df = seed_trend_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_trend_df = seed_trend_df.asfreq('D', fill_value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_trend_df['Date'] = seed_trend_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_trend_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_data = pd.read_csv('data/external/atlanta_rh_temp.csv')\n",
    "meteo_data['Date'] = pd.to_datetime(meteo_data['Date'])\n",
    "pm25_data = pd.read_csv('data/external/fire_station_pm25_2011_2018.csv')\n",
    "pm25_data.index = pd.to_datetime(pm25_data['Date'])\n",
    "pm25_data.sort_index(inplace=True)\n",
    "pm25_data = pm25_data.asfreq('D', fill_value=np.nan)\n",
    "pm25_data['Date'] = pm25_data.index\n",
    "pm25_data.reset_index(drop=True, inplace=True)\n",
    "merged_data = pd.merge(pm25_data[['Date', 'Daily_Mean_PM2_5_Concentration']], meteo_data, how='left', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, seed_trend_df, how='left', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Daily_Mean_PM2_5_Concentration</th>\n",
       "      <th>rh_max</th>\n",
       "      <th>rh_mean</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>air_pollutant</th>\n",
       "      <th>air_pollution</th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>asthma</th>\n",
       "      <th>...</th>\n",
       "      <th>smoggy</th>\n",
       "      <th>smoke</th>\n",
       "      <th>snoring</th>\n",
       "      <th>soot</th>\n",
       "      <th>sulfate</th>\n",
       "      <th>tailpipe</th>\n",
       "      <th>throat_irritation</th>\n",
       "      <th>traffic</th>\n",
       "      <th>wheezing</th>\n",
       "      <th>wildfires</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-02-23</td>\n",
       "      <td>14.3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>62.812500</td>\n",
       "      <td>64.0</td>\n",
       "      <td>51.541667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.260694</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.030573</td>\n",
       "      <td>48.143379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.991522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.803256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-02-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.373206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.440793</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.224204</td>\n",
       "      <td>48.143379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.948572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.088195</td>\n",
       "      <td>19.863940</td>\n",
       "      <td>16.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-02-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>73.875000</td>\n",
       "      <td>67.0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.255208</td>\n",
       "      <td>30.745273</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.192357</td>\n",
       "      <td>97.791239</td>\n",
       "      <td>43.654485</td>\n",
       "      <td>37.429217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.575305</td>\n",
       "      <td>20.599642</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-26</td>\n",
       "      <td>9.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>68.708334</td>\n",
       "      <td>67.0</td>\n",
       "      <td>49.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.155223</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.191083</td>\n",
       "      <td>60.179224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.746821</td>\n",
       "      <td>48.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.145183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>71.604166</td>\n",
       "      <td>75.0</td>\n",
       "      <td>60.645833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.383459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.465669</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.835669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.497880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.259159</td>\n",
       "      <td>50.763402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Daily_Mean_PM2_5_Concentration  rh_max    rh_mean  temp_max  \\\n",
       "0 2011-02-23                            14.3    90.0  62.812500      64.0   \n",
       "1 2011-02-24                             NaN    83.0  68.000000      70.0   \n",
       "2 2011-02-25                             NaN    98.0  73.875000      67.0   \n",
       "3 2011-02-26                             9.7   100.0  68.708334      67.0   \n",
       "4 2011-02-27                             NaN    98.0  71.604166      75.0   \n",
       "\n",
       "   temp_mean  air_pollutant  air_pollution  arrhythmia     asthma  ...  \\\n",
       "0  51.541667            0.0       0.000000    0.000000  78.260694  ...   \n",
       "1  57.750000            0.0      58.373206    0.000000  89.440793  ...   \n",
       "2  58.000000            0.0       0.000000   78.255208  30.745273  ...   \n",
       "3  49.416667            0.0       0.000000    0.000000  25.155223  ...   \n",
       "4  60.645833            0.0      73.383459    0.000000  75.465669  ...   \n",
       "\n",
       "   smoggy      smoke    snoring       soot     sulfate   tailpipe  \\\n",
       "0     NaN  37.030573  48.143379   0.000000  121.991522   0.000000   \n",
       "1     NaN  35.224204  48.143379   0.000000   85.948572   0.000000   \n",
       "2     NaN  26.192357  97.791239  43.654485   37.429217   0.000000   \n",
       "3     NaN  54.191083  60.179224   0.000000   45.746821  48.833333   \n",
       "4     NaN  66.835669   0.000000   0.000000   30.497880   0.000000   \n",
       "\n",
       "   throat_irritation    traffic   wheezing  wildfires  \n",
       "0                0.0  19.803256   0.000000   0.000000  \n",
       "1                0.0  15.088195  19.863940  16.470588  \n",
       "2                0.0  23.575305  20.599642   0.000000  \n",
       "3                0.0  14.145183   0.000000   0.000000  \n",
       "4                0.0  12.259159  50.763402   0.000000  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_range(df, start_date, end_date):\n",
    "    '''\n",
    "    start_date: str, format \"%y-%m-%d\", e.g. \"2011-01-01\"\n",
    "    '''\n",
    "    return df[(df['Date']>=start_date) & (df['Date']<=end_date)].index.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = get_index_range(merged_data, '2011-01-01', '2016-12-31')\n",
    "valid_index = get_index_range(merged_data, '2017-01-01', '2017-12-31')\n",
    "test_index = get_index_range(merged_data, '2018-01-01', '2018-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_arr = merged_data.drop(['Date'], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_data_arr[0].shape\n",
    "#1+4+47 = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking = (~np.isnan(merged_data_arr)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = np.zeros((masking.shape[0], masking.shape[1]))\n",
    "for value_pos, value in np.ndenumerate(masking):\n",
    "    '''\n",
    "    value_pos: tuple (row, col)\n",
    "    value: int, 1 or 0\n",
    "    '''\n",
    "    row = value_pos[0]\n",
    "    col = value_pos[1]\n",
    "    \n",
    "    # first day, delta equals 0 \n",
    "    if row == 0:\n",
    "        delta[row, col] = 0\n",
    "    # if previous day exist \n",
    "    elif masking[row-1, col] == 1:\n",
    "        delta[row, col] = 1\n",
    "    # if previous day not exist values\n",
    "    else:\n",
    "        delta[row, col] = delta[row-1, col] + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_days = len(merged_data_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_sequence(feature_matrix, seq_len):\n",
    "    feature_sequence = []\n",
    "    total_days = len(feature_matrix)\n",
    "    for i in range(total_days - seq_len):\n",
    "#         print(i)\n",
    "        feature_sequence.append(feature_matrix[i:i+seq_len])\n",
    "    return np.array(feature_sequence)\n",
    "\n",
    "def get_label_sequence(label_arr, seq_len):\n",
    "    label_sequence = []\n",
    "    total_days = len(label_arr)\n",
    "    for i in range(total_days - seq_len):\n",
    "        label_sequence.append(label_arr[i+seq_len])\n",
    "    return np.array(label_sequence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_seq = get_feature_sequence(merged_data_arr, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_label =  merged_data[['Daily_Mean_PM2_5_Concentration']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_seq = get_label_sequence(merged_label, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na with previous value\n",
    "def pd_fillna(feature_matrix, method = 'ffill'):\n",
    "    return pd.DataFrame(feature_matrix).fillna(method='ffill').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na with zero \n",
    "def pd_fillna_zero(feature_matrix):\n",
    "    return pd.DataFrame(feature_matrix).fillna(0.).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_feature_matrix = pd_fillna(merged_data_arr)\n",
    "merged_data_feature_matrix = pd_fillna_zero(merged_data_feature_matrix)\n",
    "\n",
    "# last observation if nans, however, if not na, its itself\n",
    "last_observation_seq = get_feature_sequence(merged_data_feature_matrix, seq_len)\n",
    "masking_seq = get_feature_sequence(masking, seq_len)\n",
    "delta_seq = get_feature_sequence(delta, seq_len)\n",
    "train_valid_test_split = np.array([len(train_index)-seq_len, len(valid_index), len(test_index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.isnan(merged_data_feature_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = 'data/raw/met-search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_files_dict = {\n",
    "    'fea_seq.npy': fea_seq,\n",
    "    'last_observation_seq.npy':last_observation_seq,\n",
    "    'label_seq.npy': label_seq,\n",
    "    'masking_seq.npy': masking_seq,\n",
    "    'delta_seq.npy': delta_seq,\n",
    "    'train_valid_test_split.npy': train_valid_test_split \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in save_files_dict.keys():\n",
    "    np.save(os.path.join(save_folder, file_name), save_files_dict[file_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:airpol]",
   "language": "python",
   "name": "conda-env-airpol-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
