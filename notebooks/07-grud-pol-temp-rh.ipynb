{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(os.path.pardir)\n",
    "# load data from file \n",
    "import numpy as np \n",
    "save_file_name = ['fea_seq.npy', 'last_observation_seq.npy', 'label_seq.npy', 'masking_seq.npy',\n",
    "                   'delta_seq.npy', 'train_valid_test_split.npy']\n",
    "save_folder = 'data/raw/pol_temp_rh'\n",
    "saved_arrays = []\n",
    "for file_name in save_file_name:\n",
    "    saved_arrays.append(np.load(os.path.join(save_folder, file_name)))\n",
    "[fea_seq, last_observation_seq, label_seq, masking_seq, delta_seq, train_valid_test_split] = saved_arrays\n",
    "\n",
    "# train-test-split \n",
    "train_index = [k for k in range(train_valid_test_split[0])]\n",
    "dev_index = [k for k in range(train_valid_test_split[0], \n",
    "                               train_valid_test_split[0] + train_valid_test_split[1])]\n",
    "test_index = [k for k in range(train_valid_test_split[0] + train_valid_test_split[1],\n",
    "              train_valid_test_split[0] + train_valid_test_split[1] + train_valid_test_split[2])]\n",
    "\n",
    "def get_array_by_index_range(nparray_list, label_array, index_range):\n",
    "    '''\n",
    "    nparray_list: list of nparrays to select according to index range \n",
    "    label_array: select the labels from label array\n",
    "    '''\n",
    "    # get non-na index\n",
    "    non_na_index = []\n",
    "    for index in index_range:\n",
    "        if not np.isnan(label_array[index]):\n",
    "            non_na_index.append(index)\n",
    "    \n",
    "    return [k[non_na_index] for k in nparray_list], label_array[non_na_index].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize delta\n",
    "# we can normlize this because it's know features \n",
    "delta_seq = (delta_seq - np.mean(delta_seq)) / np.std(delta_seq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split set to train, test and dev sets \n",
    "# train set\n",
    "[fea_train, last_train, masking_train, delta_train], label_train =  get_array_by_index_range([fea_seq,last_observation_seq, masking_seq, delta_seq\n",
    "                                                                 ], label_seq, train_index)\n",
    "# dev set \n",
    "[fea_dev, last_dev, masking_dev, delta_dev], label_dev =  get_array_by_index_range([fea_seq, last_observation_seq, masking_seq, delta_seq\n",
    "                                                           ], label_seq, dev_index)\n",
    "# test set \n",
    "[fea_test, last_test, masking_test, delta_test], label_test =  get_array_by_index_range([fea_seq, last_observation_seq, masking_seq, delta_seq\n",
    "                                                              ], label_seq, test_index)\n",
    "\n",
    "def normalize_feature(fea_train, array_list):\n",
    "    \"\"\"\n",
    "    array_list: [fea_dev, fea_test, last_train, last_dev, last_test] to normalize \n",
    "    \"\"\"\n",
    "    train_mean = np.nanmean(fea_train, axis=0)\n",
    "    train_std = np.nanstd(fea_train, axis=0)\n",
    "    def norm_arr(nparr):\n",
    "        return(nparr - train_mean)/train_std\n",
    "    return (norm_arr(fea_train), [norm_arr(k) for k in array_list])\n",
    "\n",
    "fea_train, [fea_dev, fea_test, last_train, last_dev, last_test] = normalize_feature(fea_train,\n",
    "                                                                                   [fea_dev, fea_test, \n",
    "                                                                                    last_train, last_dev,\n",
    "                                                                                    last_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record mean after normalization \n",
    "x_mean_aft_nor = np.nanmean(fea_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, filter_square_matrix, bias=True):\n",
    "        '''\n",
    "        filter_square_matrix : filter square matrix, whose each elements is 0 or 1.\n",
    "        '''\n",
    "        super(FilterLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        self.filter_square_matrix = None\n",
    "        if use_gpu:\n",
    "            self.filter_square_matrix = Variable(filter_square_matrix.cuda(), requires_grad=False)\n",
    "        else:\n",
    "            self.filter_square_matrix = Variable(filter_square_matrix, requires_grad=False)\n",
    "        \n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "#         print(self.weight.data)\n",
    "#         print(self.bias.data)\n",
    "\n",
    "    def forward(self, input):\n",
    "#         print(self.filter_square_matrix.mul(self.weight))\n",
    "        return F.linear(input, self.filter_square_matrix.mul(self.weight), self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'in_features=' + str(self.in_features) \\\n",
    "            + ', out_features=' + str(self.out_features) \\\n",
    "            + ', bias=' + str(self.bias is not None) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset for grud \n",
    "def dataset_aggregation(feature_array, last_obsv, mask, delta):\n",
    "    # expand dimension of array\n",
    "    def expd(arr):\n",
    "        return np.expand_dims(arr, axis=1)\n",
    "    return np.concatenate((expd(feature_array), expd(last_obsv), expd(mask), expd(delta)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_aggregation for train, dev, test \n",
    "# train_aggr = dataset_aggregation(fea_train, last_train, masking_train, delta_train)\n",
    "train_aggr = dataset_aggregation(last_train, last_train, masking_train, delta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_aggr = dataset_aggregation(fea_dev, last_dev, masking_dev, delta_dev)\n",
    "# test_aggr = dataset_aggregation(fea_test, last_test, masking_test, delta_test)\n",
    "dev_aggr = dataset_aggregation(last_dev, last_dev, masking_dev, delta_dev)\n",
    "test_aggr = dataset_aggregation(last_test, last_test, masking_test, delta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean_aft_nor = np.expand_dims(x_mean_aft_nor, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUD(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, X_mean, output_last = True, dropout=0):\n",
    "        \"\"\"\n",
    "        Recurrent Neural Networks for Multivariate Times Series with Missing Values\n",
    "        GRU-D: GRU exploit two representations of informative missingness patterns, i.e., masking and time interval.\n",
    "        cell_size is the size of cell_state.\n",
    "        \n",
    "        GRU-D:\n",
    "            input_size: variable dimension of each time\n",
    "            hidden_size: dimension of hidden_state\n",
    "            mask_size: dimension of masking vector\n",
    "            X_mean: the mean of the historical input data\n",
    "        \"\"\"\n",
    "        \n",
    "        super(GRUD, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.delta_size = input_size\n",
    "        self.mask_size = input_size\n",
    "        \n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            self.identity = torch.eye(input_size).cuda()\n",
    "            self.zeros = Variable(torch.zeros(input_size).cuda())\n",
    "            self.X_mean = Variable(torch.Tensor(X_mean).cuda())\n",
    "        else:\n",
    "            self.identity = torch.eye(input_size)\n",
    "            self.zeros = Variable(torch.zeros(input_size))\n",
    "            self.X_mean = Variable(torch.Tensor(X_mean))\n",
    "        \n",
    "        self.zl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size)\n",
    "        self.rl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size)\n",
    "        self.hl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size)\n",
    "        \n",
    "        self.gamma_x_l = FilterLinear(self.delta_size, self.delta_size, self.identity)\n",
    "        \n",
    "#         self.gamma_h_l = nn.Linear(self.delta_size, self.delta_size)\n",
    "        self.gamma_h_l = nn.Linear(self.delta_size, input_size)\n",
    "        \n",
    "        self.map_hidden_gamma = nn.Linear(input_size, 1)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def step(self, x, x_last_obsv, x_mean, h, mask, delta):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        dim_size = x.shape[1]\n",
    "        \n",
    "        delta_x = torch.exp(-torch.max(self.zeros, self.gamma_x_l(delta)))\n",
    "        \n",
    "#         delta_h = torch.exp(-torch.max(self.zeros, self.gamma_h_l(delta)))\n",
    "        \n",
    "        tmp = F.relu(self.gamma_h_l(delta))\n",
    "                     \n",
    "#         print(\"tmp size\")\n",
    "#         print(tmp.size())\n",
    "        delta_h = F.sigmoid(self.map_hidden_gamma(tmp))\n",
    "        \n",
    "#         print(\"size of the tensor\")\n",
    "# #         print(delta_h.size())\n",
    "# #         print(h.size())\n",
    "#         print(mask.size())\n",
    "#         print(x.size())\n",
    "        x = mask * x + (1 - mask) * (delta_x * x_last_obsv + (1 - delta_x) * x_mean)\n",
    "#         print(x.size())\n",
    "\n",
    "        h = delta_h * h \n",
    "        \n",
    "        \n",
    "        combined = torch.cat((x, h, mask), 1)\n",
    "        z = torch.sigmoid(self.zl(combined))\n",
    "        r = torch.sigmoid(self.rl(combined))\n",
    "        combined_r = torch.cat((x, r * h, mask), 1)\n",
    "        h_tilde = torch.tanh(self.hl(combined_r))\n",
    "        h = (1 - z) * h + z * h_tilde\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        type_size = input.size(1)\n",
    "        step_size = input.size(2)\n",
    "        spatial_size = input.size(3)\n",
    "        \n",
    "        Hidden_State = self.initHidden(batch_size)\n",
    "        \n",
    "        def squeeze_d1(matrix):\n",
    "            return torch.squeeze(matrix, dim=1)\n",
    "        X = squeeze_d1(input[:,0,:,:])\n",
    "        X_last_obsv = squeeze_d1(input[:,1,:,:])\n",
    "        Mask = squeeze_d1(input[:,2,:,:])\n",
    "        Delta = squeeze_d1(input[:,3,:,:])\n",
    "        \n",
    "        outputs = None\n",
    "        for i in range(step_size):\n",
    "#             print(\"x_mean size: \")\n",
    "#             print(self.X_mean.size())\n",
    "            Hidden_State = self.step(squeeze_d1(X[:,i:i+1,:])\\\n",
    "                                     , squeeze_d1(X_last_obsv[:,i:i+1,:])\\\n",
    "                                     , squeeze_d1(self.X_mean[:,i:i+1,:])\\\n",
    "                                     , Hidden_State\\\n",
    "                                     , squeeze_d1(Mask[:,i:i+1,:])\\\n",
    "                                     , squeeze_d1(Delta[:,i:i+1,:]))\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "                \n",
    "        if self.output_last:\n",
    "            last_hs = outputs[:,-1,:]\n",
    "            output = F.relu(self.fc1(last_hs))\n",
    "            output = self.dropout(output)\n",
    "            output = self.fc2(output)\n",
    "            return output\n",
    "        else:\n",
    "            raise Exception(\"Not output last\")\n",
    "\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_grud(X_train, y_train, X_valid, y_valid, X_test, y_test, config, x_mean_aft_nor, dropout = 0):\n",
    "    # no shuffle, keep original order \n",
    "    # swap axes for back propagation \n",
    "#     def swap_axes(nparr):\n",
    "#         return nparr.swapaxes(0,1)\n",
    "#     X_train = swap_axes(X_train)\n",
    "#     X_valid = swap_axes(X_valid)\n",
    "#     X_test = swap_axes(X_test)\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = X_train.shape[3]\n",
    "    h = config[\"h\"]\n",
    "    t = X_train.shape[2]\n",
    "    output_dim = 1\n",
    "    dropout = config[\"drop\"]\n",
    "    \n",
    "    model = GRUD(input_size, h, x_mean_aft_nor, output_last = True, dropout=dropout)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    device = torch.device('cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", patience=10, factor=0.5, verbose=True)\n",
    "    \n",
    "    def train(model, batchsize, X_train, y_train, optimizer, criterion):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        total_n = X_train.shape[0]\n",
    "        num_batches = math.ceil(total_n / batchsize)\n",
    "        for batch in range(num_batches):\n",
    "            start = batch*batchsize\n",
    "            end = (batch+1)*batchsize\n",
    "            optimizer.zero_grad()\n",
    "            batch_X = torch.Tensor(X_train[start:end, :])\n",
    "            batch_y = torch.Tensor(y_train[start:end])\n",
    "            predictions = model.forward(batch_X).squeeze(1)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        return epoch_loss / num_batches \n",
    "    \n",
    "    def evaluate(model, X_valid, y_valid, criterion):\n",
    "        epoch_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_X = torch.Tensor(X_valid)\n",
    "            batch_y = torch.Tensor(y_valid)\n",
    "            predictions = model.forward(batch_X).squeeze(1)\n",
    "            epoch_loss = criterion(predictions, batch_y).item()\n",
    "        return epoch_loss\n",
    "\n",
    "    def predict(model, X_test):\n",
    "        epoch_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_X = torch.Tensor(X_test)\n",
    "            predictions = model.forward(batch_X).squeeze(1)\n",
    "            predictions = predictions.cpu().data.numpy()\n",
    "        return predictions\n",
    "\n",
    "    # timing\n",
    "#     start_time = time.time()\n",
    "#     predictions = predict(model, X_test)\n",
    "#     print(predictions.shape)\n",
    "#     print(predictions)\n",
    "#     end_time = time.time()\n",
    "#     print(end_time-start_time)\n",
    "#     assert False\n",
    "     \n",
    "    best_valid = 999999.0\n",
    "    rand = random.randint(0,100000)\n",
    "    print('epoch train_loss valid_loss')\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        train_loss = train(model, config[\"batchsize\"], X_train, y_train, optimizer, criterion)\n",
    "        valid_loss = evaluate(model, X_valid, y_valid, criterion)\n",
    "        scheduler.step(valid_loss)\n",
    "        if valid_loss <= best_valid:\n",
    "            # save model\n",
    "            best_valid = valid_loss\n",
    "            print(epoch, train_loss, valid_loss, 'saving model')\n",
    "            torch.save(model, 'models/lstm_%d.pt' %rand)\n",
    "        else:\n",
    "            print(epoch, train_loss, valid_loss)\n",
    "\n",
    "    model = torch.load('models/lstm_%d.pt' %rand)\n",
    "\n",
    "    predictions = predict(model, X_test)\n",
    "    mae = np.mean(np.absolute(predictions-y_test))\n",
    "    print(\"mae: \", mae)\n",
    "    mse = np.mean((predictions - y_test)**2)\n",
    "    print(\"mse: \", mse)\n",
    "#     corr = np.corrcoef(predictions,y_test)[0][1]\n",
    "#     print(\"corr: \", corr)\n",
    "#     true_label = (y_test >= 0)\n",
    "#     sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(664, 4, 7, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aggr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch train_loss valid_loss\n",
      "0 133.33462887718565 80.87443542480469 saving model\n",
      "1 68.56081962585449 23.746416091918945 saving model\n",
      "2 28.369781993684313 18.945987701416016 saving model\n",
      "3 28.651712917146227 18.251468658447266 saving model\n",
      "4 28.738173257736932 18.22455596923828 saving model\n",
      "5 28.101305734543573 18.211265563964844 saving model\n",
      "6 27.468635332016717 18.14546775817871 saving model\n",
      "7 28.362816401890345 18.124650955200195 saving model\n",
      "8 25.59222312200637 18.010473251342773 saving model\n",
      "9 27.79572382427397 17.94111442565918 saving model\n",
      "10 27.88450658889044 17.96630859375\n",
      "11 26.56873643965948 17.980318069458008\n",
      "12 26.44509052094959 17.950965881347656\n",
      "13 26.525264921642485 17.96689796447754\n",
      "14 26.09368860153925 17.86954689025879 saving model\n",
      "15 27.163856324695406 17.89993667602539\n",
      "16 26.398082823980424 17.776470184326172 saving model\n",
      "17 25.75294862474714 17.72072982788086 saving model\n",
      "18 26.268256323678152 17.7122745513916 saving model\n",
      "19 25.52647572471982 17.945091247558594\n",
      "20 25.812728700183687 17.86091423034668\n",
      "21 25.28342101687477 17.645605087280273 saving model\n",
      "22 24.773527327037993 17.986818313598633\n",
      "23 26.11206545148577 17.756975173950195\n",
      "24 25.222788356599352 17.7572021484375\n",
      "25 26.30550379980178 17.88237190246582\n",
      "26 24.999769119989303 17.693777084350586\n",
      "27 25.2122768674578 17.695392608642578\n",
      "28 25.21439011891683 17.613813400268555 saving model\n",
      "29 24.731338319324312 17.581329345703125 saving model\n",
      "30 24.218942188081286 17.6383113861084\n",
      "31 24.402700378781272 17.7038631439209\n",
      "32 24.301921435764857 17.67576789855957\n",
      "33 23.430084319341752 17.763578414916992\n",
      "34 23.37633773258754 17.43736457824707 saving model\n",
      "35 22.973504202706472 17.87490463256836\n",
      "36 23.361027899242583 18.219097137451172\n",
      "37 23.653572672889347 17.30317497253418 saving model\n",
      "38 22.459679512750533 17.17938232421875 saving model\n",
      "39 22.890106882367814 17.56468391418457\n",
      "40 23.201233818417503 17.044109344482422 saving model\n",
      "41 22.09791860126314 16.8908634185791 saving model\n",
      "42 20.790750639779226 17.139326095581055\n",
      "43 21.453899928501674 16.91335105895996\n",
      "44 22.23430515470959 17.04866600036621\n",
      "45 21.699428967067174 16.987215042114258\n",
      "46 21.427235921223957 16.85128402709961 saving model\n",
      "47 22.864714667910622 16.907522201538086\n",
      "48 21.904508318219865 16.75221824645996 saving model\n",
      "49 21.3683591570173 16.979995727539062\n",
      "50 20.23802680060977 16.789955139160156\n",
      "51 21.928169659205846 16.76529312133789\n",
      "52 21.98787257784889 16.797164916992188\n",
      "53 21.453704016549246 16.88377571105957\n",
      "54 20.934316135588148 17.039926528930664\n",
      "55 20.238985561189196 16.902647018432617\n",
      "56 21.274313881283714 17.16608238220215\n",
      "57 20.75300371079218 16.81096076965332\n",
      "58 20.727119354974654 17.166213989257812\n",
      "Epoch    60: reducing learning rate of group 0 to 5.0000e-04.\n",
      "59 20.49509943099249 16.873106002807617\n",
      "60 20.350717408316477 17.210298538208008\n",
      "61 19.508304232642764 17.226104736328125\n",
      "62 20.46059649331229 17.014066696166992\n",
      "63 19.30917944226946 17.213960647583008\n",
      "64 19.789975257146928 17.185379028320312\n",
      "65 20.011520567394438 17.246063232421875\n",
      "66 19.703985441298713 17.38248062133789\n",
      "67 20.137501943679084 17.382814407348633\n",
      "68 19.248517853873118 17.230087280273438\n",
      "69 19.715004285176594 17.443687438964844\n",
      "Epoch    71: reducing learning rate of group 0 to 2.5000e-04.\n",
      "70 19.366065161568777 17.3361759185791\n",
      "71 17.918973831903365 17.63596534729004\n",
      "72 18.623428889683314 17.67139434814453\n",
      "73 18.491742088681175 17.60561180114746\n",
      "74 19.71509025210426 17.65164566040039\n",
      "75 19.59803054446266 17.56437110900879\n",
      "76 19.48011825198219 17.553756713867188\n",
      "77 18.941667942773726 17.657838821411133\n",
      "78 19.20418902805873 17.572704315185547\n",
      "79 18.782986186799548 17.791641235351562\n",
      "80 19.17018222808838 17.97574234008789\n",
      "Epoch    82: reducing learning rate of group 0 to 1.2500e-04.\n",
      "81 20.29438064211891 17.46660614013672\n",
      "82 19.965039071582613 17.668624877929688\n",
      "83 19.34529181889125 17.843564987182617\n",
      "84 18.939046723502024 17.74205207824707\n",
      "85 19.50261992499942 17.824716567993164\n",
      "86 19.154242197672527 17.759550094604492\n",
      "87 19.29052816118513 17.862051010131836\n",
      "88 19.51122504188901 17.874984741210938\n",
      "89 18.44166633061 17.68887710571289\n",
      "90 18.834940728687105 17.750656127929688\n",
      "91 18.83979992639451 17.829360961914062\n",
      "Epoch    93: reducing learning rate of group 0 to 6.2500e-05.\n",
      "92 17.864948408944265 17.81119728088379\n",
      "93 18.83885165623256 17.87500762939453\n",
      "94 17.677753244127548 17.88727569580078\n",
      "95 18.104557900201705 17.928190231323242\n",
      "96 19.33374904450916 17.961929321289062\n",
      "97 18.61411022004627 17.872074127197266\n",
      "98 18.255158333551314 18.02420997619629\n",
      "99 19.102090290614537 17.950271606445312\n",
      "mae:  2.950132933529941\n",
      "mse:  13.638366451789567\n"
     ]
    }
   ],
   "source": [
    "config = {'h':128, 'lr':0.001, 'num_epochs':100, 'batchsize':32, 'drop':0.5}\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_grud(train_aggr, label_train, dev_aggr, label_dev, test_aggr, label_test, config, x_mean_aft_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(64, 1,2,7)\n",
    "\n",
    "b = torch.randn(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 2, 7])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = a[:,:,:,2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 2, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:airpol]",
   "language": "python",
   "name": "conda-env-airpol-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
