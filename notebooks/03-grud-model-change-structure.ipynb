{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(os.path.pardir)\n",
    "# load data from file \n",
    "import numpy as np \n",
    "save_file_name = ['fea_seq.npy', 'last_observation_seq.npy', 'label_seq.npy', 'masking_seq.npy',\n",
    "                   'delta_seq.npy', 'train_valid_test_split.npy']\n",
    "save_folder = 'data/raw'\n",
    "saved_arrays = []\n",
    "for file_name in save_file_name:\n",
    "    saved_arrays.append(np.load(os.path.join(save_folder, file_name)))\n",
    "[fea_seq, last_observation_seq, label_seq, masking_seq, delta_seq, train_valid_test_split] = saved_arrays\n",
    "\n",
    "# train-test-split \n",
    "train_index = [k for k in range(train_valid_test_split[0])]\n",
    "dev_index = [k for k in range(train_valid_test_split[0], \n",
    "                               train_valid_test_split[0] + train_valid_test_split[1])]\n",
    "test_index = [k for k in range(train_valid_test_split[0] + train_valid_test_split[1],\n",
    "              train_valid_test_split[0] + train_valid_test_split[1] + train_valid_test_split[2])]\n",
    "\n",
    "def get_array_by_index_range(nparray_list, label_array, index_range):\n",
    "    '''\n",
    "    nparray_list: list of nparrays to select according to index range \n",
    "    label_array: select the labels from label array\n",
    "    '''\n",
    "    # get non-na index\n",
    "    non_na_index = []\n",
    "    for index in index_range:\n",
    "        if not np.isnan(label_array[index]):\n",
    "            non_na_index.append(index)\n",
    "    \n",
    "    return [k[non_na_index] for k in nparray_list], label_array[non_na_index].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize delta\n",
    "\n",
    "delta_seq = (delta_seq - np.mean(delta_seq)) / np.std(delta_seq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split set to train, test and dev sets \n",
    "# train set\n",
    "[fea_train, last_train, masking_train, delta_train], label_train =  get_array_by_index_range([fea_seq,last_observation_seq, masking_seq, delta_seq\n",
    "                                                                 ], label_seq, train_index)\n",
    "# dev set \n",
    "[fea_dev, last_dev, masking_dev, delta_dev], label_dev =  get_array_by_index_range([fea_seq, last_observation_seq, masking_seq, delta_seq\n",
    "                                                           ], label_seq, dev_index)\n",
    "# test set \n",
    "[fea_test, last_test, masking_test, delta_test], label_test =  get_array_by_index_range([fea_seq, last_observation_seq, masking_seq, delta_seq\n",
    "                                                              ], label_seq, test_index)\n",
    "\n",
    "def normalize_feature(fea_train, array_list):\n",
    "    \"\"\"\n",
    "    array_list: [fea_dev, fea_test, last_train, last_dev, last_test] to normalize \n",
    "    \"\"\"\n",
    "    train_mean = np.nanmean(fea_train, axis=0)\n",
    "    train_std = np.nanstd(fea_train, axis=0)\n",
    "    def norm_arr(nparr):\n",
    "        return(nparr - train_mean)/train_std\n",
    "    return (norm_arr(fea_train), [norm_arr(k) for k in array_list])\n",
    "\n",
    "fea_train, [fea_dev, fea_test, last_train, last_dev, last_test] = normalize_feature(fea_train,\n",
    "                                                                                   [fea_dev, fea_test, \n",
    "                                                                                    last_train, last_dev,\n",
    "                                                                                    last_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record mean after normalization \n",
    "x_mean_aft_nor = np.nanmean(fea_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, filter_square_matrix, bias=True):\n",
    "        '''\n",
    "        filter_square_matrix : filter square matrix, whose each elements is 0 or 1.\n",
    "        '''\n",
    "        super(FilterLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        self.filter_square_matrix = None\n",
    "        if use_gpu:\n",
    "            self.filter_square_matrix = Variable(filter_square_matrix.cuda(), requires_grad=False)\n",
    "        else:\n",
    "            self.filter_square_matrix = Variable(filter_square_matrix, requires_grad=False)\n",
    "        \n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "#         print(self.weight.data)\n",
    "#         print(self.bias.data)\n",
    "\n",
    "    def forward(self, input):\n",
    "#         print(self.filter_square_matrix.mul(self.weight))\n",
    "        return F.linear(input, self.filter_square_matrix.mul(self.weight), self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'in_features=' + str(self.in_features) \\\n",
    "            + ', out_features=' + str(self.out_features) \\\n",
    "            + ', bias=' + str(self.bias is not None) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUD(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, X_mean, output_last = True, dropout=0):\n",
    "        \"\"\"\n",
    "        Recurrent Neural Networks for Multivariate Times Series with Missing Values\n",
    "        GRU-D: GRU exploit two representations of informative missingness patterns, i.e., masking and time interval.\n",
    "        cell_size is the size of cell_state.\n",
    "        \n",
    "        GRU-D:\n",
    "            input_size: variable dimension of each time\n",
    "            hidden_size: dimension of hidden_state\n",
    "            mask_size: dimension of masking vector\n",
    "            X_mean: the mean of the historical input data\n",
    "        \"\"\"\n",
    "        \n",
    "        super(GRUD, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.delta_size = input_size\n",
    "        self.mask_size = input_size\n",
    "        \n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            self.identity = torch.eye(input_size).cuda()\n",
    "            self.zeros = Variable(torch.zeros(input_size).cuda())\n",
    "            self.X_mean = Variable(torch.Tensor(X_mean).cuda())\n",
    "        else:\n",
    "            self.identity = torch.eye(input_size)\n",
    "            self.zeros = Variable(torch.zeros(input_size))\n",
    "            self.X_mean = Variable(torch.Tensor(X_mean))\n",
    "        \n",
    "        self.zl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size)\n",
    "        self.rl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size)\n",
    "        self.hl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size)\n",
    "        \n",
    "        self.gamma_x_l = FilterLinear(self.delta_size, self.delta_size, self.identity)\n",
    "        \n",
    "#         self.gamma_h_l = nn.Linear(self.delta_size, self.delta_size)\n",
    "        self.gamma_h_l = nn.Linear(self.delta_size, input_size)\n",
    "        self.map_hidden_gamma = nn.Linear(input_size, 1)\n",
    "    \n",
    "        self.output_last = output_last\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def step(self, x, x_last_obsv, x_mean, h, mask, delta):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        dim_size = x.shape[1]\n",
    "        \n",
    "        delta_x = torch.exp(-torch.max(self.zeros, self.gamma_x_l(delta)))\n",
    "#         delta_h = torch.exp(-torch.max(self.zeros, self.gamma_h_l(delta)))\n",
    "        delta_h = F.sigmoid(self.map_hidden_gamma(F.relu(self.gamma_h_l(delta))))\n",
    "    \n",
    "        x = mask * x + (1 - mask) * (delta_x * x_last_obsv + (1 - delta_x) * x_mean)\n",
    "        h = delta_h * h\n",
    "        \n",
    "        combined = torch.cat((x, h, mask), 1)\n",
    "        z = torch.sigmoid(self.zl(combined))\n",
    "        r = torch.sigmoid(self.rl(combined))\n",
    "        combined_r = torch.cat((x, r * h, mask), 1)\n",
    "        h_tilde = torch.tanh(self.hl(combined_r))\n",
    "        h = (1 - z) * h + z * h_tilde\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        type_size = input.size(1)\n",
    "        step_size = input.size(2)\n",
    "        spatial_size = input.size(3)\n",
    "        \n",
    "        Hidden_State = self.initHidden(batch_size)\n",
    "        \n",
    "        def squeeze_d1(matrix):\n",
    "            return torch.squeeze(matrix, dim=1)\n",
    "        X = squeeze_d1(input[:,0,:,:])\n",
    "        X_last_obsv = squeeze_d1(input[:,1,:,:])\n",
    "        Mask = squeeze_d1(input[:,2,:,:])\n",
    "        Delta = squeeze_d1(input[:,3,:,:])\n",
    "        \n",
    "        outputs = None\n",
    "        for i in range(step_size):\n",
    "#             print(\"x_mean size: \")\n",
    "#             print(self.X_mean.size())\n",
    "            Hidden_State = self.step(squeeze_d1(X[:,i:i+1,:])\\\n",
    "                                     , squeeze_d1(X_last_obsv[:,i:i+1,:])\\\n",
    "                                     , squeeze_d1(self.X_mean[:,i:i+1,:])\\\n",
    "                                     , Hidden_State\\\n",
    "                                     , squeeze_d1(Mask[:,i:i+1,:])\\\n",
    "                                     , squeeze_d1(Delta[:,i:i+1,:]))\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "                \n",
    "        if self.output_last:\n",
    "            last_hs = outputs[:,-1,:]\n",
    "            output = F.relu(self.fc1(last_hs))\n",
    "            output = self.dropout(output)\n",
    "            output = self.fc2(output)\n",
    "            return output\n",
    "        else:\n",
    "            raise Exception(\"Not output last\")\n",
    "\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset for grud \n",
    "def dataset_aggregation(feature_array, last_obsv, mask, delta):\n",
    "    # expand dimension of array\n",
    "    def expd(arr):\n",
    "        return np.expand_dims(arr, axis=1)\n",
    "    return np.concatenate((expd(feature_array), expd(last_obsv), expd(mask), expd(delta)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_aggregation for train, dev, test \n",
    "# train_aggr = dataset_aggregation(fea_train, last_train, masking_train, delta_train)\n",
    "train_aggr = dataset_aggregation(last_train, last_train, masking_train, delta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_aggr = dataset_aggregation(fea_dev, last_dev, masking_dev, delta_dev)\n",
    "# test_aggr = dataset_aggregation(fea_test, last_test, masking_test, delta_test)\n",
    "dev_aggr = dataset_aggregation(last_dev, last_dev, masking_dev, delta_dev)\n",
    "test_aggr = dataset_aggregation(last_test, last_test, masking_test, delta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aggr[0:1,:].shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean_aft_nor = np.expand_dims(x_mean_aft_nor, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_grud(X_train, y_train, X_valid, y_valid, X_test, y_test, config, x_mean_aft_nor, dropout = 0):\n",
    "    # no shuffle, keep original order \n",
    "    # swap axes for back propagation \n",
    "#     def swap_axes(nparr):\n",
    "#         return nparr.swapaxes(0,1)\n",
    "#     X_train = swap_axes(X_train)\n",
    "#     X_valid = swap_axes(X_valid)\n",
    "#     X_test = swap_axes(X_test)\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = X_train.shape[3]\n",
    "    h = config[\"h\"]\n",
    "    t = X_train.shape[2]\n",
    "    output_dim = 1\n",
    "    dropout = config[\"drop\"]\n",
    "    \n",
    "    model = GRUD(input_size, h, x_mean_aft_nor, output_last = True, dropout=dropout)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    device = torch.device('cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", patience=10, factor=0.5, verbose=True)\n",
    "    \n",
    "    def train(model, batchsize, X_train, y_train, optimizer, criterion):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        total_n = X_train.shape[0]\n",
    "        num_batches = math.ceil(total_n / batchsize)\n",
    "        for batch in range(num_batches):\n",
    "            start = batch*batchsize\n",
    "            end = (batch+1)*batchsize\n",
    "            optimizer.zero_grad()\n",
    "            batch_X = torch.Tensor(X_train[start:end, :])\n",
    "            batch_y = torch.Tensor(y_train[start:end])\n",
    "            predictions = model.forward(batch_X).squeeze(1)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        return epoch_loss / num_batches \n",
    "    \n",
    "    def evaluate(model, X_valid, y_valid, criterion):\n",
    "        epoch_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_X = torch.Tensor(X_valid)\n",
    "            batch_y = torch.Tensor(y_valid)\n",
    "            predictions = model.forward(batch_X).squeeze(1)\n",
    "            epoch_loss = criterion(predictions, batch_y).item()\n",
    "        return epoch_loss\n",
    "\n",
    "    def predict(model, X_test):\n",
    "        epoch_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_X = torch.Tensor(X_test)\n",
    "            predictions = model.forward(batch_X).squeeze(1)\n",
    "            predictions = predictions.cpu().data.numpy()\n",
    "        return predictions\n",
    "\n",
    "    # timing\n",
    "#     start_time = time.time()\n",
    "#     predictions = predict(model, X_test)\n",
    "#     print(predictions.shape)\n",
    "#     print(predictions)\n",
    "#     end_time = time.time()\n",
    "#     print(end_time-start_time)\n",
    "#     assert False\n",
    "     \n",
    "    best_valid = 999999.0\n",
    "    rand = random.randint(0,100000)\n",
    "    print('epoch train_loss valid_loss')\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        train_loss = train(model, config[\"batchsize\"], X_train, y_train, optimizer, criterion)\n",
    "        valid_loss = evaluate(model, X_valid, y_valid, criterion)\n",
    "        scheduler.step(valid_loss)\n",
    "        if valid_loss <= best_valid:\n",
    "            # save model\n",
    "            best_valid = valid_loss\n",
    "            print(epoch, train_loss, valid_loss, 'saving model')\n",
    "            torch.save(model, 'models/lstm_%d.pt' %rand)\n",
    "        else:\n",
    "            print(epoch, train_loss, valid_loss)\n",
    "\n",
    "    model = torch.load('models/lstm_%d.pt' %rand)\n",
    "\n",
    "    predictions = predict(model, X_test)\n",
    "    mae = np.mean(np.absolute(predictions-y_test))\n",
    "    print(\"mae: \", mae)\n",
    "    mse = np.mean((predictions - y_test)**2)\n",
    "    print(\"mse: \", mse)\n",
    "#     corr = np.corrcoef(predictions,y_test)[0][1]\n",
    "#     print(\"corr: \", corr)\n",
    "#     true_label = (y_test >= 0)\n",
    "#     sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mean_aft_nor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch train_loss valid_loss\n",
      "0 141.65313030424574 104.05646514892578 saving model\n",
      "1 108.03573608398438 21.32916831970215 saving model\n",
      "2 41.925663811819895 20.999757766723633 saving model\n",
      "3 33.34139537811279 20.955001831054688 saving model\n",
      "4 30.021575246538436 19.638164520263672 saving model\n",
      "5 27.361787796020508 19.539934158325195 saving model\n",
      "6 27.529537200927734 19.331161499023438 saving model\n",
      "7 27.241213435218448 19.228540420532227 saving model\n",
      "8 27.75025785536993 19.499244689941406\n",
      "9 27.175868760971795 19.805326461791992\n",
      "10 27.191706929888046 19.35921287536621\n",
      "11 27.815851075308665 19.558612823486328\n",
      "12 28.162511144365585 19.797725677490234\n",
      "13 27.953765415009997 18.989456176757812 saving model\n",
      "14 26.307694753011067 19.114524841308594\n",
      "15 28.49278363727388 18.976253509521484 saving model\n",
      "16 26.82362751733689 19.181400299072266\n",
      "17 27.328934760320756 19.086830139160156\n",
      "18 27.109894934154692 18.79352378845215 saving model\n",
      "19 27.121563684372674 18.912046432495117\n",
      "20 27.156935192289808 19.161819458007812\n",
      "21 27.243902478899276 18.79521942138672\n",
      "22 27.449728102911088 18.858257293701172\n",
      "23 27.33285059247698 18.8553409576416\n",
      "24 27.3631017321632 18.763669967651367 saving model\n",
      "25 25.923823765345983 18.853078842163086\n",
      "26 26.564503805977957 18.883054733276367\n",
      "27 27.261941546485538 18.79036521911621\n",
      "28 26.990607397896902 18.749387741088867 saving model\n",
      "29 26.35894811721075 18.885154724121094\n",
      "30 27.537110283261253 18.8604793548584\n",
      "31 26.68632984161377 18.598609924316406 saving model\n",
      "32 26.5829439163208 19.15851593017578\n",
      "33 27.479854402087984 19.07235336303711\n",
      "34 26.6729120526995 18.748613357543945\n",
      "35 26.831911314101447 18.77216339111328\n",
      "36 28.14705698830741 19.068824768066406\n",
      "37 27.511836642310733 18.938682556152344\n",
      "38 26.915703092302596 18.594114303588867 saving model\n",
      "39 26.57117816380092 18.803560256958008\n",
      "40 26.039864176795597 18.761703491210938\n",
      "41 27.302415121169318 18.750606536865234\n",
      "42 26.458972476777575 18.857559204101562\n",
      "43 26.62135410308838 18.593233108520508 saving model\n",
      "44 26.891873495919363 18.668651580810547\n",
      "45 26.601540928795224 18.702106475830078\n",
      "46 28.267262958344958 18.89881706237793\n",
      "47 27.10934929620652 18.96634292602539\n",
      "48 27.048538117181685 18.78693962097168\n",
      "Epoch    50: reducing learning rate of group 0 to 5.0000e-04.\n",
      "49 25.43554741995675 18.877105712890625\n",
      "mae:  3.543314063647562\n",
      "mse:  18.179586260111158\n"
     ]
    }
   ],
   "source": [
    "config = {'h':128, 'lr':0.001, 'num_epochs':50, 'batchsize':32, 'drop':0.5}\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_grud(train_aggr, label_train, dev_aggr, label_dev, test_aggr, label_test, config, x_mean_aft_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch train_loss valid_loss\n",
      "0 144.09613000778924 112.28630065917969 saving model\n",
      "1 143.30677759079705 111.55638122558594 saving model\n",
      "2 142.51056598481676 110.79736328125 saving model\n",
      "3 141.60945311046783 109.93473815917969 saving model\n",
      "4 140.5901391165597 108.89582061767578 saving model\n",
      "5 139.3742937360491 107.51197052001953 saving model\n",
      "6 137.61573973156158 105.55892181396484 saving model\n",
      "7 135.25978379022507 102.72268676757812 saving model\n",
      "8 131.56709362211683 98.08820343017578 saving model\n",
      "9 125.22598520914714 89.62700653076172 saving model\n",
      "10 113.65036828177315 73.9071044921875 saving model\n",
      "11 93.41203689575195 52.07622146606445 saving model\n",
      "12 70.14385414123535 35.50328826904297 saving model\n",
      "13 52.85699953351702 26.624557495117188 saving model\n",
      "14 42.01252442314511 21.877925872802734 saving model\n",
      "15 35.05150236402239 19.378318786621094 saving model\n",
      "16 32.28873820531936 18.186214447021484 saving model\n",
      "17 28.633030528113956 17.746469497680664 saving model\n",
      "18 28.058009510948544 17.7139949798584 saving model\n",
      "19 27.216539519173757 17.874530792236328\n",
      "20 26.88344937279111 18.082529067993164\n",
      "21 25.70840563092913 18.29402732849121\n",
      "22 25.99390170687721 18.44550895690918\n",
      "23 27.115379242669967 18.58595848083496\n",
      "24 25.931588490804035 18.696491241455078\n",
      "25 26.47777648199172 18.754596710205078\n",
      "26 26.16776502700079 18.789718627929688\n",
      "27 25.664913086664107 18.783254623413086\n",
      "28 25.81522764478411 18.821430206298828\n",
      "Epoch    30: reducing learning rate of group 0 to 5.0000e-05.\n",
      "29 26.783132553100586 18.845806121826172\n",
      "30 26.39972804841541 18.85045051574707\n",
      "31 25.379626047043573 18.858421325683594\n",
      "32 26.582955632890975 18.863750457763672\n",
      "33 26.25661323184059 18.86872100830078\n",
      "34 26.12972722734724 18.87668800354004\n",
      "35 26.08494168236142 18.905118942260742\n",
      "36 24.803148405892507 18.921388626098633\n",
      "37 25.79754538763137 18.941204071044922\n",
      "38 26.103511083693732 18.948471069335938\n",
      "39 26.268742788405646 18.934494018554688\n",
      "Epoch    41: reducing learning rate of group 0 to 2.5000e-05.\n",
      "40 26.50045771825881 18.924028396606445\n",
      "41 26.120178449721564 18.91893196105957\n",
      "42 26.169327100118 18.907926559448242\n",
      "43 27.138863699776785 18.894607543945312\n",
      "44 26.132085391453334 18.89594078063965\n",
      "45 25.254767690386092 18.89596176147461\n",
      "46 26.93148594810849 18.895849227905273\n",
      "47 25.74541446140834 18.8938045501709\n",
      "48 26.2378937403361 18.897119522094727\n",
      "49 26.052241824922106 18.893882751464844\n",
      "mae:  3.6097934407636156\n",
      "mse:  18.50284117175752\n"
     ]
    }
   ],
   "source": [
    "config = {'h':64, 'lr':0.0001, 'num_epochs':50, 'batchsize':32, 'drop':0.2}\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_grud(train_aggr, label_train, dev_aggr, label_dev, test_aggr, label_test, config, x_mean_aft_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'h':32, 'lr':0.0001, 'num_epochs':50, 'batchsize':32, 'drop':0}\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_grud(train_aggr, label_train, dev_aggr, label_dev, test_aggr, label_test, config, x_mean_aft_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'h':64, 'lr':0.0001, 'num_epochs':50, 'batchsize':32, 'drop':0}\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_grud(train_aggr, label_train, dev_aggr, label_dev, test_aggr, label_test, config, x_mean_aft_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'h':128, 'lr':0.0001, 'num_epochs':50, 'batchsize':32, 'drop':0}\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_grud(train_aggr, label_train, dev_aggr, label_dev, test_aggr, label_test, config, x_mean_aft_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_train[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:airpol]",
   "language": "python",
   "name": "conda-env-airpol-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
