{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, filter_square_matrix, bias=True):\n",
    "        '''\n",
    "        filter_square_matrix : filter square matrix, whose each elements is 0 or 1.\n",
    "        '''\n",
    "        super(FilterLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        self.filter_square_matrix = None\n",
    "        if use_gpu:\n",
    "            self.filter_square_matrix = Variable(filter_square_matrix.cuda(), requires_grad=False)\n",
    "        else:\n",
    "            self.filter_square_matrix = Variable(filter_square_matrix, requires_grad=False)\n",
    "        \n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "#         print(self.weight.data)\n",
    "#         print(self.bias.data)\n",
    "\n",
    "    def forward(self, input):\n",
    "#         print(self.filter_square_matrix.mul(self.weight))\n",
    "        return F.linear(input, self.filter_square_matrix.mul(self.weight), self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'in_features=' + str(self.in_features) \\\n",
    "            + ', out_features=' + str(self.out_features) \\\n",
    "            + ', bias=' + str(self.bias is not None) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(os.path.pardir)\n",
    "# load data from file \n",
    "import numpy as np \n",
    "save_file_name = ['fea_seq.npy', 'last_observation_seq.npy', 'label_seq.npy', 'masking_seq.npy',\n",
    "                   'delta_seq.npy', 'train_valid_test_split.npy']\n",
    "save_folder = 'data/raw/predict-one-day-diff/pol-met-search'\n",
    "saved_arrays = []\n",
    "for file_name in save_file_name:\n",
    "    saved_arrays.append(np.load(os.path.join(save_folder, file_name)))\n",
    "[fea_seq, last_observation_seq, label_seq, masking_seq, delta_seq, train_valid_test_split] = saved_arrays\n",
    "\n",
    "# train-test-split \n",
    "train_index = [k for k in range(train_valid_test_split[0])]\n",
    "dev_index = [k for k in range(train_valid_test_split[0], \n",
    "                               train_valid_test_split[0] + train_valid_test_split[1])]\n",
    "test_index = [k for k in range(train_valid_test_split[0] + train_valid_test_split[1],\n",
    "              train_valid_test_split[0] + train_valid_test_split[1] + train_valid_test_split[2])]\n",
    "\n",
    "def get_array_by_index_range(nparray_list, label_array, index_range):\n",
    "    '''\n",
    "    nparray_list: list of nparrays to select according to index range \n",
    "    label_array: select the labels from label array\n",
    "    '''\n",
    "    # get non-na index\n",
    "    non_na_index = []\n",
    "    for index in index_range:\n",
    "        if not np.isnan(label_array[index]):\n",
    "            non_na_index.append(index)\n",
    "    \n",
    "    return [k[non_na_index] for k in nparray_list], label_array[non_na_index].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize delta\n",
    "# we can normlize this because it's know features \n",
    "delta_seq = (delta_seq - np.mean(delta_seq)) / np.std(delta_seq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split set to train, test and dev sets \n",
    "# train set\n",
    "[fea_train, last_train, masking_train, delta_train], label_train =  get_array_by_index_range([fea_seq,last_observation_seq, masking_seq, delta_seq\n",
    "                                                                 ], label_seq, train_index)\n",
    "# dev set \n",
    "[fea_dev, last_dev, masking_dev, delta_dev], label_dev =  get_array_by_index_range([fea_seq, last_observation_seq, masking_seq, delta_seq\n",
    "                                                           ], label_seq, dev_index)\n",
    "# test set \n",
    "[fea_test, last_test, masking_test, delta_test], label_test =  get_array_by_index_range([fea_seq, last_observation_seq, masking_seq, delta_seq\n",
    "                                                              ], label_seq, test_index)\n",
    "\n",
    "def normalize_feature(fea_train, array_list):\n",
    "    \"\"\"\n",
    "    array_list: [fea_dev, fea_test, last_train, last_dev, last_test] to normalize \n",
    "    \"\"\"\n",
    "    train_mean = np.nanmean(fea_train, axis=0)\n",
    "    train_std = np.nanstd(fea_train, axis=0)\n",
    "    def norm_arr(nparr):\n",
    "        return(nparr - train_mean)/train_std\n",
    "    return (norm_arr(fea_train), [norm_arr(k) for k in array_list])\n",
    "\n",
    "fea_train, [fea_dev, fea_test, last_train, last_dev, last_test] = normalize_feature(fea_train,\n",
    "                                                                                   [fea_dev, fea_test, \n",
    "                                                                                    last_train, last_dev,\n",
    "                                                                                    last_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record mean after normalization \n",
    "x_mean_aft_nor = np.nanmean(fea_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset for grud \n",
    "def dataset_aggregation(feature_array, last_obsv, mask, delta):\n",
    "    # expand dimension of array\n",
    "    def expd(arr):\n",
    "        return np.expand_dims(arr, axis=1)\n",
    "    return np.concatenate((expd(feature_array), expd(last_obsv), expd(mask), expd(delta)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_aggregation for train, dev, test \n",
    "# train_aggr = dataset_aggregation(fea_train, last_train, masking_train, delta_train)\n",
    "train_aggr = dataset_aggregation(last_train, last_train, masking_train, delta_train)\n",
    "# dev_aggr = dataset_aggregation(fea_dev, last_dev, masking_dev, delta_dev)\n",
    "# test_aggr = dataset_aggregation(fea_test, last_test, masking_test, delta_test)\n",
    "dev_aggr = dataset_aggregation(last_dev, last_dev, masking_dev, delta_dev)\n",
    "test_aggr = dataset_aggregation(last_test, last_test, masking_test, delta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(664, 4, 7, 52)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aggr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mfn(X_train, y_train, X_valid, y_valid, X_test, y_test, configs, X_mean):\n",
    "#     p = np.random.permutation(X_train.shape[0])\n",
    "    # no shuffle, keep original order \n",
    "    # swap axes for back propagation \n",
    "#     def swap_axes(nparr):\n",
    "#         return nparr.swapaxes(0,1)\n",
    "#     X_train = swap_axes(X_train)\n",
    "#     X_valid = swap_axes(X_valid)\n",
    "#     X_test = swap_axes(X_test)\n",
    "    \n",
    "    # model parameters \n",
    "    input_size = X_train.shape[3]\n",
    "    h = 32\n",
    "    t = X_train.shape[2]\n",
    "    output_dim = 1\n",
    "    dropout = 0.5\n",
    "\n",
    "#     d = X_train.shape[2]\n",
    "#     h = 128\n",
    "#     t = X_train.shape[0]\n",
    "#     output_dim = 1\n",
    "#     dropout = 0.5\n",
    "\n",
    "    [config,NN1Config,NN2Config,gamma1Config,gamma2Config,outConfig] = configs\n",
    "\n",
    "    \n",
    "    #model = EFLSTM(d,h,output_dim,dropout)\n",
    "    model = MFN(config,NN1Config,NN2Config,gamma1Config,gamma2Config,outConfig, X_mean)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),lr=config[\"lr\"])\n",
    "    #optimizer = optim.SGD(model.parameters(),lr=config[\"lr\"],momentum=config[\"momentum\"])\n",
    "\n",
    "    # optimizer = optim.SGD([\n",
    "    #                 {'params':model.lstm_l.parameters(), 'lr':config[\"lr\"]},\n",
    "    #                 {'params':model.classifier.parameters(), 'lr':config[\"lr\"]}\n",
    "    #             ], momentum=0.9)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    device = torch.device('cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", patience=10, factor=0.5, verbose=True)\n",
    "    \n",
    "#     criterion = nn.L1Loss()\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     model = model.to(device)\n",
    "#     criterion = criterion.to(device)\n",
    "#     scheduler = ReduceLROnPlateau(optimizer,mode='min',patience=100,factor=0.5,verbose=True)\n",
    "\n",
    "    def train(model, batchsize, X_train, y_train, optimizer, criterion):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        total_n = X_train.shape[0]\n",
    "        num_batches = math.ceil(total_n / batchsize)\n",
    "        for batch in range(num_batches):\n",
    "            start = batch*batchsize\n",
    "            end = (batch+1)*batchsize\n",
    "            optimizer.zero_grad()\n",
    "            batch_X = torch.Tensor(X_train[start:end,:])\n",
    "            batch_y = torch.Tensor(y_train[start:end])\n",
    "            predictions = model.forward(batch_X).squeeze(1)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        return epoch_loss / num_batches\n",
    "\n",
    "    def evaluate(model, X_valid, y_valid, criterion):\n",
    "        epoch_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_X = torch.Tensor(X_valid)\n",
    "            batch_y = torch.Tensor(y_valid)\n",
    "            predictions = model.forward(batch_X).squeeze(1)\n",
    "            epoch_loss = criterion(predictions, batch_y).item()\n",
    "        return epoch_loss\n",
    "\n",
    "    def predict(model, X_test):\n",
    "        epoch_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_X = torch.Tensor(X_test)\n",
    "            predictions = model.forward(batch_X).squeeze(1)\n",
    "            predictions = predictions.cpu().data.numpy()\n",
    "        return predictions\n",
    "\n",
    "    best_valid = 999999.0\n",
    "    rand = random.randint(0,100000)\n",
    "    print('epoch train_loss valid_loss')\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        train_loss = train(model, config[\"batchsize\"], X_train, y_train, optimizer, criterion)\n",
    "        valid_loss = evaluate(model, X_valid, y_valid, criterion)\n",
    "        scheduler.step(valid_loss)\n",
    "        if valid_loss <= best_valid:\n",
    "            # save model\n",
    "            best_valid = valid_loss\n",
    "            print(epoch, train_loss, valid_loss, 'saving model')\n",
    "            torch.save(model, 'models/temp_models/mfn_%d.pt' %rand)\n",
    "        else:\n",
    "            print(epoch, train_loss, valid_loss)\n",
    "\n",
    "#     print 'model number is:', rand\n",
    "    model = torch.load('models/temp_models/mfn_%d.pt' %rand)\n",
    "\n",
    "    predictions = predict(model, X_test)\n",
    "    mae = np.mean(np.absolute(predictions-y_test))\n",
    "    print(\"mae: \", mae)\n",
    "    mse = np.mean((predictions - y_test)**2)\n",
    "    print(\"mse: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUD(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, X_mean, output_last = True, dropout=0):\n",
    "        \"\"\"\n",
    "        Recurrent Neural Networks for Multivariate Times Series with Missing Values\n",
    "        GRU-D: GRU exploit two representations of informative missingness patterns, i.e., masking and time interval.\n",
    "        cell_size is the size of cell_state.\n",
    "        \n",
    "        GRU-D:\n",
    "            input_size: variable dimension of each time\n",
    "            hidden_size: dimension of hidden_state\n",
    "            mask_size: dimension of masking vector\n",
    "            X_mean: the mean of the historical input data\n",
    "        \"\"\"\n",
    "        super(GRUD, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.delta_size = input_size\n",
    "        self.mask_size = input_size\n",
    "        \n",
    "        self.identity = torch.eye(input_size)\n",
    "        self.zeros = Variable(torch.zeros(input_size))\n",
    "        \n",
    "        self.zl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size)\n",
    "        self.rl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size)\n",
    "        self.hl = nn.Linear(input_size + hidden_size + self.mask_size, hidden_size)\n",
    "        \n",
    "        self.gamma_x_l = FilterLinear(self.delta_size, self.delta_size, self.identity)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "#     def forward(self, x, x_last_obsv, x_mean, h, mask, delta):\n",
    "    # use input to feed the four dimensions \n",
    "    def forward(self, dataset, X_mean, h):\n",
    "        \"\"\"\n",
    "        dataset: matrix shape (n * c * d)\n",
    "                    n: batchsize; c: class; d number of dims\n",
    "        \"\"\"\n",
    "        x_mean = Variable(torch.Tensor(X_mean))\n",
    "        batch_size = dataset.size(0)\n",
    "        dim_size = dataset.size(2)\n",
    "    \n",
    "        x = dataset[:,0,:]\n",
    "        x_last_obsv = dataset[:,1,:]\n",
    "        mask = dataset[:,2,:]\n",
    "        delta = dataset[:,3,:]\n",
    "        \n",
    "        delta_x = torch.exp(-torch.max(self.zeros, self.gamma_x_l(delta)))\n",
    "        \n",
    "                # concat the info \n",
    "        concat_info = torch.cat([delta,h], dim=1)\n",
    "        \n",
    "#         delta_h = F.sigmoid(self.map_hidden_gamma(F.relu(self.gamma_h_l(concat_info))))\n",
    "        \n",
    "        x = mask * x + (1 - mask) * (delta_x * x_last_obsv + (1 - delta_x) * x_mean)\n",
    "        \n",
    "        combined = torch.cat((x, h, mask), 1)\n",
    "        z = torch.sigmoid(self.zl(combined))\n",
    "        r = torch.sigmoid(self.rl(combined))\n",
    "        combined_r = torch.cat((x, r * h, mask), 1)\n",
    "        h_tilde = torch.tanh(self.hl(combined_r))\n",
    "        h = (1 - z) * h + z * h_tilde\n",
    "        \n",
    "        return h\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFN(nn.Module):\n",
    "    def __init__(self,config,NN1Config,NN2Config,gamma1Config,gamma2Config,outConfig, X_mean):\n",
    "        super(MFN, self).__init__()\n",
    "        [self.d_l,self.d_a] = config[\"input_dims\"]\n",
    "        [self.dh_l,self.dh_a] = config[\"h_dims\"]\n",
    "        total_h_dim = self.dh_l+self.dh_a\n",
    "        \n",
    "        self.mem_dim = config[\"memsize\"]\n",
    "        window_dim = config[\"windowsize\"]\n",
    "        output_dim = 1\n",
    "        attInShape = total_h_dim*window_dim\n",
    "        gammaInShape = attInShape+self.mem_dim\n",
    "        final_out = total_h_dim+self.mem_dim\n",
    "        h_att1 = NN1Config[\"shapes\"]\n",
    "        h_att2 = NN2Config[\"shapes\"]\n",
    "        h_gamma1 = gamma1Config[\"shapes\"]\n",
    "        h_gamma2 = gamma2Config[\"shapes\"]\n",
    "        h_out = outConfig[\"shapes\"]\n",
    "        att1_dropout = NN1Config[\"drop\"]\n",
    "        att2_dropout = NN2Config[\"drop\"]\n",
    "        gamma1_dropout = gamma1Config[\"drop\"]\n",
    "        gamma2_dropout = gamma2Config[\"drop\"]\n",
    "        out_dropout = outConfig[\"drop\"]\n",
    "    \n",
    "        # use grud cell instead of LSTM Cell\n",
    "#         (self, input_size, hidden_size, X_mean, output_last = True, dropout=0):\n",
    "        self.gru_l = GRUD(self.d_l, self.dh_l, X_mean)\n",
    "        self.gru_a = GRUD(self.d_a, self.dh_a, X_mean)\n",
    "\n",
    "        self.att1_fc1 = nn.Linear(attInShape, h_att1)\n",
    "        self.att1_fc2 = nn.Linear(h_att1, attInShape)\n",
    "        self.att1_dropout = nn.Dropout(att1_dropout)\n",
    "\n",
    "        self.att2_fc1 = nn.Linear(attInShape, h_att2)\n",
    "        self.att2_fc2 = nn.Linear(h_att2, self.mem_dim)\n",
    "        self.att2_dropout = nn.Dropout(att2_dropout)\n",
    "\n",
    "        self.gamma1_fc1 = nn.Linear(gammaInShape, h_gamma1)\n",
    "        self.gamma1_fc2 = nn.Linear(h_gamma1, self.mem_dim)\n",
    "        self.gamma1_dropout = nn.Dropout(gamma1_dropout)\n",
    "\n",
    "        self.gamma2_fc1 = nn.Linear(gammaInShape, h_gamma2)\n",
    "        self.gamma2_fc2 = nn.Linear(h_gamma2, self.mem_dim)\n",
    "        self.gamma2_dropout = nn.Dropout(gamma2_dropout)\n",
    "\n",
    "        self.out_fc1 = nn.Linear(final_out, h_out)\n",
    "        self.out_fc2 = nn.Linear(h_out, output_dim)\n",
    "        self.out_dropout = nn.Dropout(out_dropout)\n",
    "        \n",
    "        ## add the part for grud missing imputation \n",
    "        self.x_mean = X_mean \n",
    "        self.hidden_size = self.dh_l\n",
    "        \n",
    "        \n",
    "#         ## \n",
    "#         self.gamma_decay = nn.Linear(self.d_l+self.d_a, self.hidden_size)\n",
    "#         self.map_gamma_decay = nn.Linear(self.hidden_size, 1)\n",
    "        \n",
    "        ## self concat \n",
    "        self.conc_fc1 = nn.Linear(self.mem_dim + self.dh_a, self.dh_l)\n",
    "        self.conc_fc2 = nn.Linear(self.dh_l, self.dh_l)\n",
    "        self.conc_dropout = nn.Dropout(out_dropout)\n",
    "    \n",
    "    def squeeze_d2(self, matrix):\n",
    "        return torch.squeeze(matrix, dim=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x_l = x[:,:,:,:self.d_l]\n",
    "        x_a = x[:,:,:,self.d_l:self.d_l+self.d_a]\n",
    "        # x is n x c x t x d\n",
    "        # seperate x_mean_l and x_mean_a \n",
    "        x_mean_l = self.x_mean[:,:self.d_l]\n",
    "        x_mean_a = self.x_mean[:,self.d_l:self.d_l+self.d_a]\n",
    "        \n",
    "        n = x.shape[0]\n",
    "        t = x.shape[1]\n",
    "        self.h_l = self.initHidden(n)\n",
    "        self.h_a = self.initHidden(n)\n",
    "        \n",
    "        self.mem = torch.zeros(n, self.mem_dim)\n",
    "        all_h_ls = []\n",
    "        all_h_as = []\n",
    "\n",
    "        all_mems = []\n",
    "        \n",
    "        for i in range(t):\n",
    "            # prev time step\n",
    "            prev_h_l = self.h_l\n",
    "            prev_h_a = self.h_a\n",
    "\n",
    "            new_h_a = self.gru_a(self.squeeze_d2(x_a[:,:,i:i+1,:]), x_mean_a[i:i+1,:], prev_h_a)\n",
    "            new_h_l = self.gru_l(self.squeeze_d2(x_l[:,:,i:i+1,:]), x_mean_l[i:i+1,:], prev_h_l)\n",
    "\n",
    "            # concatenate\n",
    "            prev_hs = torch.cat([prev_h_l,prev_h_a], dim=1)\n",
    "            new_hs = torch.cat([new_h_l,new_h_a], dim=1)\n",
    "            \n",
    "            cStar = torch.cat([prev_hs,new_hs], dim=1)\n",
    "            attention = F.softmax(self.att1_fc2(self.att1_dropout(F.relu(self.att1_fc1(cStar)))),dim=1)\n",
    "            attended = attention*cStar\n",
    "            \n",
    "            cHat = F.tanh(self.att2_fc2(self.att2_dropout(F.relu(self.att2_fc1(attended)))))\n",
    "            \n",
    "            both = torch.cat([attended,self.mem], dim=1)\n",
    "            gamma1 = F.sigmoid(self.gamma1_fc2(self.gamma1_dropout(F.relu(self.gamma1_fc1(both)))))\n",
    "            gamma2 = F.sigmoid(self.gamma2_fc2(self.gamma2_dropout(F.relu(self.gamma2_fc1(both)))))\n",
    "        \n",
    "            self.mem = gamma1*self.mem + gamma2*cHat\n",
    "        \n",
    "            \n",
    "            all_mems.append(self.mem)\n",
    "            # update\n",
    "            self.h_l = new_h_l\n",
    "            self.h_a = new_h_a\n",
    "\n",
    "            all_h_ls.append(self.h_l)\n",
    "            all_h_as.append(self.h_a)\n",
    "\n",
    "        # last hidden layer last_hs is n x h\n",
    "        last_h_l = all_h_ls[-1]\n",
    "        last_h_a = all_h_as[-1]\n",
    "\n",
    "        last_mem = all_mems[-1]\n",
    "        last_hs = torch.cat([last_h_l,last_h_a,last_mem], dim=1)\n",
    "        output = self.out_fc2(self.out_dropout(F.relu(self.out_fc1(last_hs))))\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_mean_aft_nor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch train_loss valid_loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flynn/Documents/Desktop/softs/miniconda/envs/airpol/lib/python3.6/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/Users/flynn/Documents/Desktop/softs/miniconda/envs/airpol/lib/python3.6/site-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 41.11747287568592 33.46942901611328 saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flynn/Documents/Desktop/softs/miniconda/envs/airpol/lib/python3.6/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type MFN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/flynn/Documents/Desktop/softs/miniconda/envs/airpol/lib/python3.6/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type GRUD. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/flynn/Documents/Desktop/softs/miniconda/envs/airpol/lib/python3.6/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type FilterLinear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 40.63723496028355 33.328948974609375 saving model\n",
      "2 40.32084333328974 33.411808013916016\n",
      "3 40.0659297761463 33.2172737121582 saving model\n",
      "4 39.613859857831685 33.034759521484375 saving model\n",
      "5 39.68572521209717 32.805362701416016 saving model\n",
      "6 39.20474143255325 32.586002349853516 saving model\n",
      "7 38.56295617421468 32.217735290527344 saving model\n",
      "8 38.14326486133394 32.06496810913086 saving model\n",
      "9 37.59837395804269 32.03621292114258 saving model\n",
      "10 37.51492691040039 32.089385986328125\n",
      "11 37.230841591244655 32.59043884277344\n",
      "12 36.46292913527716 33.0416145324707\n",
      "13 36.376202719552175 33.61353302001953\n",
      "14 35.57835415431431 34.26703643798828\n",
      "15 36.37819226582845 34.275306701660156\n",
      "16 36.223612739926295 34.60523223876953\n",
      "17 35.548665001278835 35.258949279785156\n",
      "18 35.40875434875488 35.468223571777344\n",
      "19 34.747352191380095 36.3029670715332\n",
      "Epoch    21: reducing learning rate of group 0 to 5.0000e-04.\n",
      "20 34.410556248256135 36.79269027709961\n",
      "21 33.887126014346165 37.179656982421875\n",
      "22 34.42762733641125 37.58260726928711\n",
      "23 33.61777587164016 37.70903778076172\n",
      "24 34.01526996067592 37.978843688964844\n",
      "25 33.36114570072719 38.565616607666016\n",
      "26 33.53413436526344 38.782230377197266\n",
      "27 32.44080847785587 39.245819091796875\n",
      "28 33.25295448303223 39.14026641845703\n",
      "29 32.93394370306106 39.12747573852539\n",
      "30 32.24280352819534 39.34083938598633\n",
      "Epoch    32: reducing learning rate of group 0 to 2.5000e-04.\n",
      "31 32.26535533723377 39.42495346069336\n",
      "32 31.4189270564488 39.680362701416016\n",
      "33 30.943700154622395 40.40810012817383\n",
      "34 31.336775371006556 40.34333038330078\n",
      "35 31.038734617687407 40.356693267822266\n",
      "36 31.18398970649356 40.38596725463867\n",
      "37 31.41773491814023 40.57898712158203\n",
      "38 30.65330918629964 40.65887451171875\n",
      "39 30.931140763419016 40.6484489440918\n",
      "40 30.577532722836448 40.91349411010742\n",
      "41 30.083772432236444 40.81229782104492\n",
      "Epoch    43: reducing learning rate of group 0 to 1.2500e-04.\n",
      "42 29.86279664720808 40.99931716918945\n",
      "43 29.143069948468888 41.2260627746582\n",
      "44 29.622790926978702 41.3458137512207\n",
      "45 29.208184560139973 41.57901382446289\n",
      "46 29.37373247600737 41.78422546386719\n",
      "47 29.059265227544877 41.65258026123047\n",
      "48 29.307729039873397 41.90425491333008\n",
      "49 29.286332811628068 41.94482421875\n",
      "mae:  4.351746701424527\n",
      "mse:  29.84462534883167\n"
     ]
    }
   ],
   "source": [
    "# pol + met \n",
    "config = dict()\n",
    "config[\"input_dims\"] = [1, 4]\n",
    "hl = 128\n",
    "ha = 128\n",
    "drop = 0.5\n",
    "config[\"h_dims\"] = [hl, ha]\n",
    "config[\"memsize\"] = hl\n",
    "config[\"windowsize\"] = 2\n",
    "config[\"batchsize\"] = 32\n",
    "config[\"num_epochs\"] = 50\n",
    "config[\"lr\"] = 0.001\n",
    "NN1Config = dict()\n",
    "NN1Config[\"shapes\"] = hl\n",
    "NN1Config[\"drop\"] = drop\n",
    "NN2Config = dict()\n",
    "NN2Config[\"shapes\"] = 32\n",
    "NN2Config[\"drop\"] = drop\n",
    "gamma1Config = dict()\n",
    "gamma1Config[\"shapes\"] = hl\n",
    "gamma1Config[\"drop\"] = drop\n",
    "gamma2Config = dict()\n",
    "gamma2Config[\"shapes\"] = hl \n",
    "gamma2Config[\"drop\"] = drop\n",
    "outConfig = dict() \n",
    "outConfig[\"shapes\"] = hl\n",
    "outConfig[\"drop\"] = drop\n",
    "configs = [config,NN1Config,NN2Config,gamma1Config,gamma2Config,outConfig]\n",
    "\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "train_mfn(train_aggr[:,:,:,0:5], label_train, dev_aggr[:,:,:,0:5], label_dev, test_aggr[:,:,:,0:5], label_test, configs, x_mean_aft_nor[:, 0:5])\n",
    "# train_grud(train_aggr, label_train, dev_aggr, label_dev, test_aggr, label_test, config, x_mean_aft_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:airpol]",
   "language": "python",
   "name": "conda-env-airpol-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
